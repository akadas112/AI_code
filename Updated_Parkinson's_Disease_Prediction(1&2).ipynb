{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akadas112/AI_code/blob/main/Updated_Parkinson's_Disease_Prediction(1%262).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6qQ0OG1lFPw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np # linear algebra\n",
        " \n",
        "import seaborn as sns #data visualisation \n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "pkbd43r5nlhd",
        "outputId": "2d8edfa1-8882-4464-ab40-1a2d5f6e5584"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9bb5f4f9-064a-471c-bb78-a360e319578f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9bb5f4f9-064a-471c-bb78-a360e319578f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Questionaries _dataset(1&2) - Sheet1.csv to Questionaries _dataset(1&2) - Sheet1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7shvIU5o8m9"
      },
      "source": [
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded['Questionaries _dataset(1&2) - Sheet1.csv']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "thKpiOZXqNOL",
        "outputId": "2fbc53d0-ccc5-4e4e-d657-92a4e76934fe"
      },
      "source": [
        "data.head(10).T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PAT_NO</th>\n",
              "      <td>3000</td>\n",
              "      <td>3000</td>\n",
              "      <td>3000</td>\n",
              "      <td>3000</td>\n",
              "      <td>3000</td>\n",
              "      <td>3000</td>\n",
              "      <td>3000</td>\n",
              "      <td>3001</td>\n",
              "      <td>3001</td>\n",
              "      <td>3001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Event_ID</th>\n",
              "      <td>BL</td>\n",
              "      <td>V04</td>\n",
              "      <td>V06</td>\n",
              "      <td>V08</td>\n",
              "      <td>V10</td>\n",
              "      <td>V12</td>\n",
              "      <td>V15</td>\n",
              "      <td>BL</td>\n",
              "      <td>SC</td>\n",
              "      <td>V01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP1SLPN</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP1SLPD</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP1PAIN</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP1URIN</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP1CNST</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP1LTHD</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP1FATG</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Partition</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2SPCH</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2SALV</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2SWAL</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2EAT</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2DRES</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2HYGN</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2HWRT</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2HOBB</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2TURN</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2TRMR</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2RISE</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2WALK</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NP2FREZ</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Status</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0     1     2     3     4     5     6     7     8     9\n",
              "PAT_NO     3000  3000  3000  3000  3000  3000  3000  3001  3001  3001\n",
              "Event_ID     BL   V04   V06   V08   V10   V12   V15    BL    SC   V01\n",
              "NP1SLPN       1     0     2     3     1     1     1     1     0     1\n",
              "NP1SLPD       2     2     1     2     1     2     0     2     1     2\n",
              "NP1PAIN       0     0     0     0     1     0     0     0     0     0\n",
              "NP1URIN       0     1     0     1     1     3     1     4     4     3\n",
              "NP1CNST       0     0     0     0     1     1     0     0     0     0\n",
              "NP1LTHD       0     0     0     0     0     0     0     0     0     0\n",
              "NP1FATG       0     1     0     0     1     1     0     1     1     1\n",
              "Partition   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
              "NP2SPCH       0     0     0     0     0     0     0     0     0     0\n",
              "NP2SALV       0     0     0     0     0     0     0     0     0     0\n",
              "NP2SWAL       0     0     0     0     0     0     0     0     0     0\n",
              "NP2EAT        0     0     0     0     0     0     0     0     0     0\n",
              "NP2DRES       0     0     0     0     0     0     0     1     0     0\n",
              "NP2HYGN       0     0     0     0     0     0     0     0     0     0\n",
              "NP2HWRT       0     0     0     0     0     0     0     0     0     0\n",
              "NP2HOBB       0     0     0     0     0     0     0     0     1     1\n",
              "NP2TURN       0     0     0     0     0     0     0     0     0     0\n",
              "NP2TRMR       0     0     0     0     0     0     0     1     1     1\n",
              "NP2RISE       0     0     0     0     0     0     0     0     0     0\n",
              "NP2WALK       0     0     0     0     0     0     0     0     0     0\n",
              "NP2FREZ       0     0     0     0     0     0     0     0     0     0\n",
              "Status        0     0     0     0     0     0     0     1     1     1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_g5NhDHjDZl",
        "outputId": "bed1e03a-ed6a-40b0-cc24-63a75dfb5480"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7146, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "hfxsyrv-k5Cd",
        "outputId": "e4ccca5e-ad8c-41c8-d598-7eacebc307e6"
      },
      "source": [
        "sns.countplot(data['Status'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff9bde99410>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHk8wfZUlhR-",
        "outputId": "530ad782-3789-4f3e-bbf2-a7e281f6559c"
      },
      "source": [
        "data['Status'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5887\n",
              "0    1259\n",
              "Name: Status, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1RVfN0pnr5_"
      },
      "source": [
        "**Filling Missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BldQO6y9hNOV",
        "outputId": "0cfc8ebc-dd31-4620-c5f7-81ed2bacd43a"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PAT_NO          0\n",
              "Event_ID        0\n",
              "NP1SLPN         1\n",
              "NP1SLPD         1\n",
              "NP1PAIN         1\n",
              "NP1URIN         1\n",
              "NP1CNST         0\n",
              "NP1LTHD         0\n",
              "NP1FATG         0\n",
              "Partition    7146\n",
              "NP2SPCH         0\n",
              "NP2SALV         0\n",
              "NP2SWAL         0\n",
              "NP2EAT          3\n",
              "NP2DRES         3\n",
              "NP2HYGN         3\n",
              "NP2HWRT         3\n",
              "NP2HOBB         5\n",
              "NP2TURN         1\n",
              "NP2TRMR         1\n",
              "NP2RISE         1\n",
              "NP2WALK         0\n",
              "NP2FREZ         0\n",
              "Status          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4xOAN6XMyI5"
      },
      "source": [
        "data = data.fillna(data.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIVwlr_UkIGZ"
      },
      "source": [
        "**Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kk791cuwju9"
      },
      "source": [
        "X = data.drop(['PAT_NO','Event_ID', 'Partition', 'Status' ], axis=1)\n",
        "y = data['Status'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2zzK0GsbnjI",
        "outputId": "74430242-6045-4a9c-c75e-ac804ed937f7"
      },
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      NP1SLPN  NP1SLPD  NP1PAIN  NP1URIN  ...  NP2TRMR  NP2RISE  NP2WALK  NP2FREZ\n",
            "0         1.0      2.0      0.0      0.0  ...      0.0      0.0        0        0\n",
            "1         0.0      2.0      0.0      1.0  ...      0.0      0.0        0        0\n",
            "2         2.0      1.0      0.0      0.0  ...      0.0      0.0        0        0\n",
            "3         3.0      2.0      0.0      1.0  ...      0.0      0.0        0        0\n",
            "4         1.0      1.0      1.0      1.0  ...      0.0      0.0        0        0\n",
            "...       ...      ...      ...      ...  ...      ...      ...      ...      ...\n",
            "7141      2.0      2.0      2.0      0.0  ...      1.0      1.0        0        0\n",
            "7142      4.0      2.0      3.0      1.0  ...      1.0      1.0        1        1\n",
            "7143      0.0      0.0      0.0      0.0  ...      0.0      0.0        0        0\n",
            "7144      0.0      0.0      1.0      0.0  ...      0.0      0.0        0        0\n",
            "7145      0.0      1.0      0.0      0.0  ...      0.0      0.0        0        0\n",
            "\n",
            "[7146 rows x 20 columns]\n",
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qF_IiovtSfX"
      },
      "source": [
        "#from sklearn.ensemble import ExtraTreesClassifier\n",
        "#import matplotlib.pyplot as plt\n",
        "#model = ExtraTreesClassifier()\n",
        "#model.fit(X,y)\n",
        "#print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
        "#plot graph of feature importances for better visualization\n",
        "#feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "#feat_importances.nlargest(20).plot(kind='barh')\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrlig8I4cQDk"
      },
      "source": [
        "#get correlations of each features in dataset\n",
        "#corrmat = data.corr()\n",
        "#top_corr_features = corrmat.index\n",
        "#plt.figure(figsize=(23,23))\n",
        "#plot heat map\n",
        "#g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CeGYO4AuM9h"
      },
      "source": [
        "**Scalling & Balancing the Data set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ClOOABAFvG4"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlILCSVSGVex"
      },
      "source": [
        "feature_X = StandardScaler().fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxwbC8zdbPjN"
      },
      "source": [
        "#pip install imblearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-aRCJtoYhVQ",
        "outputId": "93730e2a-232c-4eab-8c5f-1cdc417e8d28"
      },
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y == 0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before OverSampling, counts of label '1': 5887\n",
            "Before OverSampling, counts of label '0': 1259 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOGMo21ZYr26",
        "outputId": "b234c946-6457-4372-8d47-af10e8a3b065"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "#from imblearn.under_sampling import RandomUnderSampler\n",
        "#sm = RandomUnderSampler(random_state = 2)\n",
        "X_res, y_res = sm.fit_sample(feature_X, y.ravel())\n",
        "  \n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape))\n",
        "  \n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res == 0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After OverSampling, the shape of train_X: (11774, 20)\n",
            "After OverSampling, the shape of train_y: (11774,) \n",
            "\n",
            "After OverSampling, counts of label '1': 5887\n",
            "After OverSampling, counts of label '0': 5887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu-mjhYcZKl0"
      },
      "source": [
        "**Split Data Set & Stratification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGgqhaJGnWFB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=0, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx454zF1o4QI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b92db2f-24c7-4107-f75c-9d4ac8bc8848"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9419, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8HuMjfipiFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45dc477-f627-4efb-fd48-800e53abb2c5"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2355, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkkCr6f6sPkL",
        "outputId": "367475be-79d6-4970-cdf3-5f8517eb2ee1"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duC2JBSb7KsJ"
      },
      "source": [
        "**ANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfYzvxl8s3Q6"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(15,input_dim=20,activation='sigmoid'))\n",
        "model.add(Dense(20,activation='sigmoid'))\n",
        "#model.add(Dense(10,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Ct53SLz-FJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "2a1391ed-a698-4897-d70b-45be5b374e57"
      },
      "source": [
        "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-70008d9bab76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtJ0CNFm0Vfp"
      },
      "source": [
        "import h5py\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min',  verbose=1, patience=100, baseline=0.4, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlsOmBVAE5az",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054fe312-fb54-4cea-8c2a-13525b414444"
      },
      "source": [
        "history = model.fit(X_train, y_train,validation_data=(X_test,y_test),batch_size=13,epochs=200, callbacks=mc)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "725/725 [==============================] - 6s 4ms/step - loss: 0.3986 - accuracy: 0.8487 - val_loss: 0.2343 - val_accuracy: 0.9244\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.23431, saving model to best_model.h5\n",
            "Epoch 2/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1842 - accuracy: 0.9352 - val_loss: 0.1730 - val_accuracy: 0.9410\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.23431 to 0.17301, saving model to best_model.h5\n",
            "Epoch 3/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1584 - accuracy: 0.9419 - val_loss: 0.1675 - val_accuracy: 0.9435\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.17301 to 0.16748, saving model to best_model.h5\n",
            "Epoch 4/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1536 - accuracy: 0.9437 - val_loss: 0.1663 - val_accuracy: 0.9448\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.16748 to 0.16632, saving model to best_model.h5\n",
            "Epoch 5/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1517 - accuracy: 0.9436 - val_loss: 0.1664 - val_accuracy: 0.9423\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.16632\n",
            "Epoch 6/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1499 - accuracy: 0.9450 - val_loss: 0.1661 - val_accuracy: 0.9435\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.16632 to 0.16608, saving model to best_model.h5\n",
            "Epoch 7/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1490 - accuracy: 0.9447 - val_loss: 0.1652 - val_accuracy: 0.9439\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.16608 to 0.16521, saving model to best_model.h5\n",
            "Epoch 8/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1477 - accuracy: 0.9473 - val_loss: 0.1684 - val_accuracy: 0.9444\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.16521\n",
            "Epoch 9/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1466 - accuracy: 0.9460 - val_loss: 0.1665 - val_accuracy: 0.9444\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.16521\n",
            "Epoch 10/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1459 - accuracy: 0.9453 - val_loss: 0.1646 - val_accuracy: 0.9456\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.16521 to 0.16465, saving model to best_model.h5\n",
            "Epoch 11/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1451 - accuracy: 0.9469 - val_loss: 0.1623 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.16465 to 0.16231, saving model to best_model.h5\n",
            "Epoch 12/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1438 - accuracy: 0.9488 - val_loss: 0.1623 - val_accuracy: 0.9456\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.16231 to 0.16226, saving model to best_model.h5\n",
            "Epoch 13/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1433 - accuracy: 0.9490 - val_loss: 0.1625 - val_accuracy: 0.9478\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.16226\n",
            "Epoch 14/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1418 - accuracy: 0.9485 - val_loss: 0.1618 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.16226 to 0.16182, saving model to best_model.h5\n",
            "Epoch 15/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1416 - accuracy: 0.9495 - val_loss: 0.1612 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.16182 to 0.16123, saving model to best_model.h5\n",
            "Epoch 16/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1404 - accuracy: 0.9489 - val_loss: 0.1592 - val_accuracy: 0.9473\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.16123 to 0.15923, saving model to best_model.h5\n",
            "Epoch 17/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1398 - accuracy: 0.9491 - val_loss: 0.1629 - val_accuracy: 0.9469\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.15923\n",
            "Epoch 18/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1397 - accuracy: 0.9508 - val_loss: 0.1600 - val_accuracy: 0.9473\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.15923\n",
            "Epoch 19/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1384 - accuracy: 0.9502 - val_loss: 0.1574 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.15923 to 0.15743, saving model to best_model.h5\n",
            "Epoch 20/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1374 - accuracy: 0.9516 - val_loss: 0.1599 - val_accuracy: 0.9478\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.15743\n",
            "Epoch 21/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1374 - accuracy: 0.9510 - val_loss: 0.1571 - val_accuracy: 0.9490\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.15743 to 0.15713, saving model to best_model.h5\n",
            "Epoch 22/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1358 - accuracy: 0.9525 - val_loss: 0.1567 - val_accuracy: 0.9516\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.15713 to 0.15667, saving model to best_model.h5\n",
            "Epoch 23/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1352 - accuracy: 0.9522 - val_loss: 0.1572 - val_accuracy: 0.9503\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.15667\n",
            "Epoch 24/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1344 - accuracy: 0.9513 - val_loss: 0.1551 - val_accuracy: 0.9512\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.15667 to 0.15505, saving model to best_model.h5\n",
            "Epoch 25/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1342 - accuracy: 0.9529 - val_loss: 0.1548 - val_accuracy: 0.9490\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.15505 to 0.15484, saving model to best_model.h5\n",
            "Epoch 26/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1327 - accuracy: 0.9537 - val_loss: 0.1554 - val_accuracy: 0.9503\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.15484\n",
            "Epoch 27/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1325 - accuracy: 0.9536 - val_loss: 0.1545 - val_accuracy: 0.9478\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.15484 to 0.15454, saving model to best_model.h5\n",
            "Epoch 28/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1318 - accuracy: 0.9534 - val_loss: 0.1551 - val_accuracy: 0.9499\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.15454\n",
            "Epoch 29/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1312 - accuracy: 0.9542 - val_loss: 0.1545 - val_accuracy: 0.9503\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.15454 to 0.15453, saving model to best_model.h5\n",
            "Epoch 30/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1305 - accuracy: 0.9548 - val_loss: 0.1529 - val_accuracy: 0.9503\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.15453 to 0.15287, saving model to best_model.h5\n",
            "Epoch 31/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1291 - accuracy: 0.9564 - val_loss: 0.1519 - val_accuracy: 0.9503\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.15287 to 0.15191, saving model to best_model.h5\n",
            "Epoch 32/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1287 - accuracy: 0.9547 - val_loss: 0.1516 - val_accuracy: 0.9503\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.15191 to 0.15163, saving model to best_model.h5\n",
            "Epoch 33/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1281 - accuracy: 0.9562 - val_loss: 0.1499 - val_accuracy: 0.9520\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.15163 to 0.14988, saving model to best_model.h5\n",
            "Epoch 34/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1269 - accuracy: 0.9555 - val_loss: 0.1494 - val_accuracy: 0.9537\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.14988 to 0.14945, saving model to best_model.h5\n",
            "Epoch 35/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1270 - accuracy: 0.9566 - val_loss: 0.1482 - val_accuracy: 0.9520\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.14945 to 0.14821, saving model to best_model.h5\n",
            "Epoch 36/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1255 - accuracy: 0.9580 - val_loss: 0.1482 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.14821 to 0.14821, saving model to best_model.h5\n",
            "Epoch 37/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1249 - accuracy: 0.9572 - val_loss: 0.1500 - val_accuracy: 0.9495\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.14821\n",
            "Epoch 38/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1242 - accuracy: 0.9590 - val_loss: 0.1491 - val_accuracy: 0.9499\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.14821\n",
            "Epoch 39/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1227 - accuracy: 0.9559 - val_loss: 0.1467 - val_accuracy: 0.9546\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.14821 to 0.14668, saving model to best_model.h5\n",
            "Epoch 40/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1217 - accuracy: 0.9587 - val_loss: 0.1521 - val_accuracy: 0.9490\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.14668\n",
            "Epoch 41/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1219 - accuracy: 0.9577 - val_loss: 0.1476 - val_accuracy: 0.9507\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.14668\n",
            "Epoch 42/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1204 - accuracy: 0.9589 - val_loss: 0.1444 - val_accuracy: 0.9529\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.14668 to 0.14441, saving model to best_model.h5\n",
            "Epoch 43/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1197 - accuracy: 0.9598 - val_loss: 0.1500 - val_accuracy: 0.9499\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.14441\n",
            "Epoch 44/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1192 - accuracy: 0.9593 - val_loss: 0.1428 - val_accuracy: 0.9546\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.14441 to 0.14284, saving model to best_model.h5\n",
            "Epoch 45/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1181 - accuracy: 0.9597 - val_loss: 0.1427 - val_accuracy: 0.9537\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.14284 to 0.14273, saving model to best_model.h5\n",
            "Epoch 46/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1182 - accuracy: 0.9587 - val_loss: 0.1420 - val_accuracy: 0.9529\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.14273 to 0.14195, saving model to best_model.h5\n",
            "Epoch 47/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1161 - accuracy: 0.9603 - val_loss: 0.1459 - val_accuracy: 0.9516\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.14195\n",
            "Epoch 48/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1161 - accuracy: 0.9591 - val_loss: 0.1409 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.14195 to 0.14090, saving model to best_model.h5\n",
            "Epoch 49/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1147 - accuracy: 0.9610 - val_loss: 0.1431 - val_accuracy: 0.9520\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.14090\n",
            "Epoch 50/100\n",
            "725/725 [==============================] - 3s 5ms/step - loss: 0.1138 - accuracy: 0.9604 - val_loss: 0.1410 - val_accuracy: 0.9537\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.14090\n",
            "Epoch 51/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1135 - accuracy: 0.9585 - val_loss: 0.1390 - val_accuracy: 0.9546\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.14090 to 0.13902, saving model to best_model.h5\n",
            "Epoch 52/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1127 - accuracy: 0.9614 - val_loss: 0.1400 - val_accuracy: 0.9529\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.13902\n",
            "Epoch 53/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1116 - accuracy: 0.9595 - val_loss: 0.1399 - val_accuracy: 0.9529\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.13902\n",
            "Epoch 54/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1115 - accuracy: 0.9607 - val_loss: 0.1397 - val_accuracy: 0.9503\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.13902\n",
            "Epoch 55/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1102 - accuracy: 0.9607 - val_loss: 0.1386 - val_accuracy: 0.9520\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.13902 to 0.13855, saving model to best_model.h5\n",
            "Epoch 56/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1098 - accuracy: 0.9625 - val_loss: 0.1375 - val_accuracy: 0.9537\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.13855 to 0.13749, saving model to best_model.h5\n",
            "Epoch 57/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1085 - accuracy: 0.9611 - val_loss: 0.1367 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.13749 to 0.13665, saving model to best_model.h5\n",
            "Epoch 58/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1086 - accuracy: 0.9615 - val_loss: 0.1366 - val_accuracy: 0.9541\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.13665 to 0.13662, saving model to best_model.h5\n",
            "Epoch 59/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1071 - accuracy: 0.9627 - val_loss: 0.1385 - val_accuracy: 0.9495\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.13662\n",
            "Epoch 60/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1070 - accuracy: 0.9618 - val_loss: 0.1368 - val_accuracy: 0.9524\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.13662\n",
            "Epoch 61/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1061 - accuracy: 0.9618 - val_loss: 0.1382 - val_accuracy: 0.9516\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.13662\n",
            "Epoch 62/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1055 - accuracy: 0.9628 - val_loss: 0.1353 - val_accuracy: 0.9529\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.13662 to 0.13529, saving model to best_model.h5\n",
            "Epoch 63/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1054 - accuracy: 0.9610 - val_loss: 0.1344 - val_accuracy: 0.9516\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.13529 to 0.13445, saving model to best_model.h5\n",
            "Epoch 64/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1041 - accuracy: 0.9627 - val_loss: 0.1340 - val_accuracy: 0.9524\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.13445 to 0.13395, saving model to best_model.h5\n",
            "Epoch 65/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1041 - accuracy: 0.9635 - val_loss: 0.1352 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.13395\n",
            "Epoch 66/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1028 - accuracy: 0.9643 - val_loss: 0.1345 - val_accuracy: 0.9537\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.13395\n",
            "Epoch 67/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1019 - accuracy: 0.9640 - val_loss: 0.1382 - val_accuracy: 0.9516\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.13395\n",
            "Epoch 68/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1020 - accuracy: 0.9646 - val_loss: 0.1328 - val_accuracy: 0.9529\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.13395 to 0.13283, saving model to best_model.h5\n",
            "Epoch 69/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1021 - accuracy: 0.9635 - val_loss: 0.1316 - val_accuracy: 0.9550\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.13283 to 0.13160, saving model to best_model.h5\n",
            "Epoch 70/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1003 - accuracy: 0.9646 - val_loss: 0.1328 - val_accuracy: 0.9541\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.13160\n",
            "Epoch 71/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.1004 - accuracy: 0.9643 - val_loss: 0.1341 - val_accuracy: 0.9533\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.13160\n",
            "Epoch 72/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0999 - accuracy: 0.9642 - val_loss: 0.1313 - val_accuracy: 0.9554\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.13160 to 0.13132, saving model to best_model.h5\n",
            "Epoch 73/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0985 - accuracy: 0.9658 - val_loss: 0.1312 - val_accuracy: 0.9554\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.13132 to 0.13118, saving model to best_model.h5\n",
            "Epoch 74/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0981 - accuracy: 0.9663 - val_loss: 0.1326 - val_accuracy: 0.9550\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.13118\n",
            "Epoch 75/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0975 - accuracy: 0.9657 - val_loss: 0.1307 - val_accuracy: 0.9567\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.13118 to 0.13072, saving model to best_model.h5\n",
            "Epoch 76/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0974 - accuracy: 0.9649 - val_loss: 0.1306 - val_accuracy: 0.9567\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.13072 to 0.13058, saving model to best_model.h5\n",
            "Epoch 77/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0968 - accuracy: 0.9662 - val_loss: 0.1325 - val_accuracy: 0.9541\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.13058\n",
            "Epoch 78/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0966 - accuracy: 0.9655 - val_loss: 0.1304 - val_accuracy: 0.9571\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.13058 to 0.13038, saving model to best_model.h5\n",
            "Epoch 79/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0961 - accuracy: 0.9665 - val_loss: 0.1283 - val_accuracy: 0.9558\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.13038 to 0.12826, saving model to best_model.h5\n",
            "Epoch 80/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0952 - accuracy: 0.9672 - val_loss: 0.1330 - val_accuracy: 0.9550\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.12826\n",
            "Epoch 81/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0947 - accuracy: 0.9674 - val_loss: 0.1302 - val_accuracy: 0.9554\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.12826\n",
            "Epoch 82/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0949 - accuracy: 0.9666 - val_loss: 0.1284 - val_accuracy: 0.9580\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.12826\n",
            "Epoch 83/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0938 - accuracy: 0.9675 - val_loss: 0.1270 - val_accuracy: 0.9575\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.12826 to 0.12702, saving model to best_model.h5\n",
            "Epoch 84/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0936 - accuracy: 0.9673 - val_loss: 0.1320 - val_accuracy: 0.9550\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.12702\n",
            "Epoch 85/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0934 - accuracy: 0.9676 - val_loss: 0.1275 - val_accuracy: 0.9571\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.12702\n",
            "Epoch 86/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0929 - accuracy: 0.9678 - val_loss: 0.1275 - val_accuracy: 0.9588\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.12702\n",
            "Epoch 87/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0922 - accuracy: 0.9675 - val_loss: 0.1267 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.12702 to 0.12668, saving model to best_model.h5\n",
            "Epoch 88/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0918 - accuracy: 0.9672 - val_loss: 0.1293 - val_accuracy: 0.9580\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.12668\n",
            "Epoch 89/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0909 - accuracy: 0.9683 - val_loss: 0.1298 - val_accuracy: 0.9575\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.12668\n",
            "Epoch 90/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0913 - accuracy: 0.9679 - val_loss: 0.1262 - val_accuracy: 0.9575\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.12668 to 0.12618, saving model to best_model.h5\n",
            "Epoch 91/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0908 - accuracy: 0.9681 - val_loss: 0.1264 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.12618\n",
            "Epoch 92/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0913 - accuracy: 0.9680 - val_loss: 0.1297 - val_accuracy: 0.9575\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.12618\n",
            "Epoch 93/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0899 - accuracy: 0.9697 - val_loss: 0.1249 - val_accuracy: 0.9618\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.12618 to 0.12493, saving model to best_model.h5\n",
            "Epoch 94/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0898 - accuracy: 0.9687 - val_loss: 0.1292 - val_accuracy: 0.9580\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.12493\n",
            "Epoch 95/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0896 - accuracy: 0.9689 - val_loss: 0.1236 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.12493 to 0.12358, saving model to best_model.h5\n",
            "Epoch 96/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0887 - accuracy: 0.9693 - val_loss: 0.1293 - val_accuracy: 0.9580\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.12358\n",
            "Epoch 97/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0888 - accuracy: 0.9700 - val_loss: 0.1306 - val_accuracy: 0.9571\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.12358\n",
            "Epoch 98/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0886 - accuracy: 0.9705 - val_loss: 0.1277 - val_accuracy: 0.9614\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.12358\n",
            "Epoch 99/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0883 - accuracy: 0.9690 - val_loss: 0.1249 - val_accuracy: 0.9626\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.12358\n",
            "Epoch 100/100\n",
            "725/725 [==============================] - 3s 4ms/step - loss: 0.0869 - accuracy: 0.9709 - val_loss: 0.1250 - val_accuracy: 0.9618\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.12358\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 15)                315       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                320       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 656\n",
            "Trainable params: 656\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7IOa5lNb2HM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8660f149-362f-4603-dbf9-2be36194156a"
      },
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9618\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12495102733373642, 0.9617834687232971]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUaQDD-gFEEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "309cf95b-43f2-42ad-c0a2-7bb0f3ee8762"
      },
      "source": [
        "min(history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12357944995164871"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoj5rYSyA-gS"
      },
      "source": [
        "from keras.models import load_model\n",
        "saved_model = load_model('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSSTlHZGFRDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdb0f02-7243-4f55-8cb5-b9c647041772"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(\"Predicted output:.....\")\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted output:.....\n",
            "[[0.01171937]\n",
            " [0.00704128]\n",
            " [0.9999801 ]\n",
            " ...\n",
            " [0.07220766]\n",
            " [0.99999523]\n",
            " [0.7135799 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c47ugqY7FhSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f33dd298-31a4-408b-9046-831500b8bc39"
      },
      "source": [
        "from sklearn import metrics\n",
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))  \n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))  \n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('VarScore:',metrics.explained_variance_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.05704633068823999\n",
            "MSE: 0.03169444541874625\n",
            "RMSE: 0.1780293386460396\n",
            "VarScore: 0.8733298984860665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI8q1TKJFoiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caac3f09-d653-46f2-e2c9-1a52924963cc"
      },
      "source": [
        "for i in range(len(y_pred)):\n",
        "  if(y_pred[i]>0.5):\n",
        "    print('%.2f (expected %d)' % (1, y_test[i]))\n",
        " \n",
        "  else:\n",
        "        print('%.2f (expected %d)' % (0, y_test[i]))\n",
        " \n",
        " \n",
        "_, accuracy = model.evaluate(X_train,y_train.ravel())\n",
        "print('Training Accuracy: %.2f\\n\\n' % (accuracy*100))\n",
        "  \n",
        "_, accuracy = model.evaluate(X_test,y_test)\n",
        "print('Testing Accuracy: %.2f\\n\\n' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "0.00 (expected 0)\n",
            "1.00 (expected 1)\n",
            "1.00 (expected 1)\n",
            "295/295 [==============================] - 2s 5ms/step - loss: 0.0850 - accuracy: 0.9711\n",
            "Training Accuracy: 97.11\n",
            "\n",
            "\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9618\n",
            "Testing Accuracy: 96.18\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-1Dfw25YTTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f75968-8724-4534-bec2-5cc26d3fec72"
      },
      "source": [
        "score_ANN = round(accuracy_score(y_pred.round(),y_test)*100,2)\n",
        "print(\"The accuracy score achieved using ANN is: \"+str(score_ANN)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using ANN is: 96.18 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y1-Cs6Tx_xF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aadcc7fa-2756-48f4-85ff-5c845a794a0f"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred.round()))\n",
        "print(classification_report(y_test, y_pred.round()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1140   51]\n",
            " [  39 1125]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96      1191\n",
            "           1       0.96      0.97      0.96      1164\n",
            "\n",
            "    accuracy                           0.96      2355\n",
            "   macro avg       0.96      0.96      0.96      2355\n",
            "weighted avg       0.96      0.96      0.96      2355\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ1yuvdt3AQ0"
      },
      "source": [
        "**Logistic regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f23Vt_el3HX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c32c71-6fac-44d6-d3eb-a8df238164b3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr1 = LogisticRegression()\n",
        "lr1.fit(X_train, y_train.ravel())\n",
        "predictions = lr1.predict(X_test)\n",
        "  \n",
        "# print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94      1191\n",
            "           1       0.93      0.95      0.94      1164\n",
            "\n",
            "    accuracy                           0.94      2355\n",
            "   macro avg       0.94      0.94      0.94      2355\n",
            "weighted avg       0.94      0.94      0.94      2355\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTt1_CedwLDZ",
        "outputId": "4e4962cf-aa32-4392-c6c2-cf365942b86d"
      },
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9439490445859873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqENYDkq7rwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc71449e-274e-4954-8726-b5f15490fda4"
      },
      "source": [
        "score_lr = round(accuracy_score(predictions,y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using LR is: \"+str(score_lr)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using LR is: 94.39 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywFbU9gzB5rA"
      },
      "source": [
        "import pickle\n",
        "# save the model to disk\n",
        "filename = 'finalized_model_lr.sav'\n",
        "pickle.dump(lr1, open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ3mdpZCCJqR",
        "outputId": "2cc0d5c6-f6e8-4948-c41d-96b8bac5749e"
      },
      "source": [
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9439490445859873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zJAilTHwmIS"
      },
      "source": [
        "**K-Nearest Neighbour**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRnv9WwcXmXd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffbf58c-1348-43f5-807f-9c6ad860e37f"
      },
      "source": [
        "# Fitting KNN to the Training set \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn1 = KNeighborsClassifier(n_neighbors = 1, weights = 'uniform',algorithm = 'brute',metric = 'manhattan')\n",
        "knn1.fit(X_train, y_train.ravel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='manhattan',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PmdBtA564mQ"
      },
      "source": [
        "y_pred_knn = knn1.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQgoY-FdXyyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91ab321-8c6e-48a3-e7ed-e98b32de4f93"
      },
      "source": [
        "# Predictions and Evaluations \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred_knn))\n",
        "print(classification_report(y_test, y_pred_knn))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1179   12]\n",
            " [  56 1108]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      1191\n",
            "           1       0.99      0.95      0.97      1164\n",
            "\n",
            "    accuracy                           0.97      2355\n",
            "   macro avg       0.97      0.97      0.97      2355\n",
            "weighted avg       0.97      0.97      0.97      2355\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhEEvA9OYKbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a0e1aa-c354-410c-96dc-2953f9b6eefe"
      },
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9711252653927813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Di2FXrT6MCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa0bd74-172e-4e08-affb-f4d68d29a425"
      },
      "source": [
        "score_knn = round(accuracy_score(y_pred_knn,y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using KNN is: \"+str(score_knn)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using KNN is: 97.11 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvU-yJP4kER7",
        "outputId": "3fc91658-25db-444e-8c6a-4f76fb1d928c"
      },
      "source": [
        "#Hyperparameter tuning for KNN\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_params = { 'n_neighbors' : range(1, 21, 2),\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=4, n_jobs = -1)\n",
        "g_res = gs.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 60 candidates, totalling 240 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   25.4s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  2.3min finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVnt6h_SovTO",
        "outputId": "cfab62f8-b4cc-4f61-8cb9-72dbd2386185"
      },
      "source": [
        "g_res.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9644334439099008"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwMV8p_HowP3",
        "outputId": "0db80465-b159-4289-a818-8160eba67182"
      },
      "source": [
        "g_res.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TdHVuyvDknp"
      },
      "source": [
        "import pickle\n",
        "# save the model to disk\n",
        "filename1 = 'finalized_model_knn.sav'\n",
        "pickle.dump(knn1, open(filename1, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7owKxttD7Kh",
        "outputId": "7e34ff08-315d-47da-b553-b4c871d0f74b"
      },
      "source": [
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename1, 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9711252653927813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F64hqGchxs8s"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFaGgz1ktyfb"
      },
      "source": [
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn3cMHXmwEfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee24a81c-7260-4294-fce0-4cbafd09d54f"
      },
      "source": [
        "svm1 = SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
        "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        "    tol=0.001, verbose=False)\n",
        "svm1.fit(X_train, y_train.ravel())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmnwqtXkyT1C",
        "outputId": "a26e04ca-118b-4802-b100-23257f5de07e"
      },
      "source": [
        "y_pred_svm = svm1.predict(X_test)\n",
        "# Predictions and Evaluations \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1158   33]\n",
            " [  37 1127]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1191\n",
            "           1       0.97      0.97      0.97      1164\n",
            "\n",
            "    accuracy                           0.97      2355\n",
            "   macro avg       0.97      0.97      0.97      2355\n",
            "weighted avg       0.97      0.97      0.97      2355\n",
            "\n",
            "Accuracy: 0.970276008492569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPUUP3afw-Tl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b8b529d-7a83-407a-cccc-dbbff862458d"
      },
      "source": [
        "score_svm = round(accuracy_score(y_pred_svm,y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using SVM is: \"+str(score_svm)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using SVM is: 97.03 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NZACZHxs439",
        "outputId": "349c3aa6-768a-4530-eefc-ada27e8ec2a7"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "  \n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf', 'sigmoid', 'linear']} \n",
        "  \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "  \n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.865, total=   4.0s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.874, total=   3.8s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.7s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.896, total=   3.8s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.881, total=   3.7s\n",
            "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.886, total=   3.8s\n",
            "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.579, total=   4.3s\n",
            "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.583, total=   4.5s\n",
            "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.577, total=   4.3s\n",
            "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.571, total=   4.8s\n",
            "[CV] C=0.1, gamma=1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=0.1, gamma=1, kernel=sigmoid, score=0.570, total=   4.6s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.941, total=   0.4s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.944, total=   0.4s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.942, total=   0.3s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.945, total=   0.3s\n",
            "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
            "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.943, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.943, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.946, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.942, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.949, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.943, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.892, total=   1.5s\n",
            "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.901, total=   1.4s\n",
            "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.898, total=   1.4s\n",
            "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.892, total=   1.4s\n",
            "[CV] C=0.1, gamma=0.1, kernel=sigmoid ................................\n",
            "[CV] .... C=0.1, gamma=0.1, kernel=sigmoid, score=0.882, total=   1.3s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.941, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.944, total=   0.4s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.942, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.945, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
            "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.943, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.938, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.943, total=   1.2s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.939, total=   1.2s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.945, total=   1.2s\n",
            "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.943, total=   1.1s\n",
            "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.926, total=   1.5s\n",
            "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.939, total=   1.4s\n",
            "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.926, total=   1.5s\n",
            "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.941, total=   1.4s\n",
            "[CV] C=0.1, gamma=0.01, kernel=sigmoid ...............................\n",
            "[CV] ... C=0.1, gamma=0.01, kernel=sigmoid, score=0.936, total=   1.5s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.941, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.944, total=   0.4s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.942, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.945, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
            "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.943, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.883, total=   2.4s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.902, total=   2.5s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.885, total=   2.5s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.884, total=   2.4s\n",
            "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.883, total=   2.5s\n",
            "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.841, total=   3.1s\n",
            "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.865, total=   3.1s\n",
            "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.852, total=   3.1s\n",
            "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.842, total=   3.1s\n",
            "[CV] C=0.1, gamma=0.001, kernel=sigmoid ..............................\n",
            "[CV] .. C=0.1, gamma=0.001, kernel=sigmoid, score=0.852, total=   3.2s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.941, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.944, total=   0.4s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.942, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.945, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
            "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.943, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.664, total=   4.5s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.655, total=   4.5s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.667, total=   4.4s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.667, total=   4.4s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.661, total=   4.5s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=sigmoid, score=0.692, total=   4.6s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=sigmoid, score=0.661, total=   4.6s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=sigmoid, score=0.644, total=   4.6s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=sigmoid, score=0.619, total=   4.6s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=sigmoid .............................\n",
            "[CV] . C=0.1, gamma=0.0001, kernel=sigmoid, score=0.683, total=   4.5s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] .. C=0.1, gamma=0.0001, kernel=linear, score=0.941, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] .. C=0.1, gamma=0.0001, kernel=linear, score=0.944, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] .. C=0.1, gamma=0.0001, kernel=linear, score=0.942, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] .. C=0.1, gamma=0.0001, kernel=linear, score=0.945, total=   0.3s\n",
            "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] .. C=0.1, gamma=0.0001, kernel=linear, score=0.943, total=   0.3s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.965, total=   3.4s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.954, total=   3.9s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.964, total=   3.7s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.963, total=   3.7s\n",
            "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
            "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.968, total=   3.7s\n",
            "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.577, total=   4.0s\n",
            "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.583, total=   4.2s\n",
            "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.572, total=   4.2s\n",
            "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.565, total=   4.3s\n",
            "[CV] C=1, gamma=1, kernel=sigmoid ....................................\n",
            "[CV] ........ C=1, gamma=1, kernel=sigmoid, score=0.567, total=   4.3s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ......... C=1, gamma=1, kernel=linear, score=0.941, total=   0.5s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ......... C=1, gamma=1, kernel=linear, score=0.944, total=   0.6s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ......... C=1, gamma=1, kernel=linear, score=0.941, total=   0.6s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ......... C=1, gamma=1, kernel=linear, score=0.947, total=   0.5s\n",
            "[CV] C=1, gamma=1, kernel=linear .....................................\n",
            "[CV] ......... C=1, gamma=1, kernel=linear, score=0.943, total=   0.6s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.963, total=   0.8s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.961, total=   0.8s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.962, total=   0.8s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.961, total=   0.8s\n",
            "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
            "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.963, total=   0.8s\n",
            "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.887, total=   0.9s\n",
            "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.896, total=   1.0s\n",
            "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.892, total=   1.0s\n",
            "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.890, total=   1.0s\n",
            "[CV] C=1, gamma=0.1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=1, gamma=0.1, kernel=sigmoid, score=0.879, total=   0.9s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.941, total=   0.5s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.944, total=   0.5s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.941, total=   0.6s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.947, total=   0.5s\n",
            "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
            "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.943, total=   0.6s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.941, total=   0.7s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.945, total=   0.7s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.945, total=   0.7s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.947, total=   0.7s\n",
            "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
            "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.942, total=   0.7s\n",
            "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.937, total=   0.7s\n",
            "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.943, total=   0.7s\n",
            "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.941, total=   0.7s\n",
            "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.944, total=   0.8s\n",
            "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
            "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.940, total=   0.8s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.941, total=   0.5s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.944, total=   0.5s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.941, total=   0.6s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.947, total=   0.5s\n",
            "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
            "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.943, total=   0.5s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.935, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.941, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.940, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.946, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
            "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.941, total=   1.1s\n",
            "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.925, total=   1.5s\n",
            "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.940, total=   1.5s\n",
            "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.930, total=   1.4s\n",
            "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.941, total=   1.4s\n",
            "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
            "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.935, total=   1.4s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.941, total=   0.5s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.944, total=   0.5s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.941, total=   0.6s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.947, total=   0.5s\n",
            "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
            "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.943, total=   0.6s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.882, total=   2.4s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.902, total=   2.4s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.885, total=   2.4s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.884, total=   2.5s\n",
            "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
            "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.882, total=   2.4s\n",
            "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.841, total=   3.2s\n",
            "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.865, total=   3.3s\n",
            "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.852, total=   3.3s\n",
            "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.842, total=   3.4s\n",
            "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
            "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.852, total=   3.4s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.941, total=   0.6s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.944, total=   0.6s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.941, total=   0.6s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.947, total=   0.6s\n",
            "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
            "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.943, total=   0.6s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.969, total=   4.7s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.961, total=   4.1s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.967, total=   4.4s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.970, total=   4.6s\n",
            "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
            "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.971, total=   4.0s\n",
            "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
            "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.577, total=   4.1s\n",
            "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
            "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.583, total=   4.2s\n",
            "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
            "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.569, total=   4.4s\n",
            "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
            "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.565, total=   4.2s\n",
            "[CV] C=10, gamma=1, kernel=sigmoid ...................................\n",
            "[CV] ....... C=10, gamma=1, kernel=sigmoid, score=0.567, total=   4.8s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ........ C=10, gamma=1, kernel=linear, score=0.941, total=   1.7s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ........ C=10, gamma=1, kernel=linear, score=0.943, total=   1.7s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ........ C=10, gamma=1, kernel=linear, score=0.941, total=   1.8s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ........ C=10, gamma=1, kernel=linear, score=0.948, total=   1.7s\n",
            "[CV] C=10, gamma=1, kernel=linear ....................................\n",
            "[CV] ........ C=10, gamma=1, kernel=linear, score=0.944, total=   1.8s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.969, total=   0.7s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.971, total=   0.7s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.970, total=   0.7s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.967, total=   0.7s\n",
            "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
            "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.971, total=   0.7s\n",
            "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.886, total=   0.9s\n",
            "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.898, total=   1.0s\n",
            "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.892, total=   1.0s\n",
            "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.891, total=   1.0s\n",
            "[CV] C=10, gamma=0.1, kernel=sigmoid .................................\n",
            "[CV] ..... C=10, gamma=0.1, kernel=sigmoid, score=0.877, total=   1.0s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.941, total=   1.7s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.943, total=   1.7s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.941, total=   1.8s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.948, total=   1.8s\n",
            "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
            "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.944, total=   1.7s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.952, total=   0.6s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.954, total=   0.7s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.954, total=   0.7s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.956, total=   0.6s\n",
            "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
            "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.952, total=   0.6s\n",
            "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.938, total=   0.6s\n",
            "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.941, total=   0.7s\n",
            "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.939, total=   0.7s\n",
            "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.945, total=   0.7s\n",
            "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
            "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.942, total=   0.7s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.941, total=   1.7s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.943, total=   1.7s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.941, total=   1.9s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.948, total=   1.8s\n",
            "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
            "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.944, total=   1.8s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.937, total=   0.7s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.941, total=   0.7s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.940, total=   0.7s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.943, total=   0.7s\n",
            "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
            "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.940, total=   0.7s\n",
            "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
            "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.937, total=   0.8s\n",
            "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
            "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.942, total=   0.8s\n",
            "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
            "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.941, total=   0.8s\n",
            "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
            "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.944, total=   0.8s\n",
            "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
            "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.940, total=   0.8s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.941, total=   1.7s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.943, total=   1.7s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.941, total=   1.8s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.948, total=   1.7s\n",
            "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
            "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.944, total=   1.8s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.935, total=   1.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.941, total=   1.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.940, total=   1.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.945, total=   1.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
            "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.940, total=   1.2s\n",
            "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.926, total=   1.6s\n",
            "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.940, total=   1.5s\n",
            "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.930, total=   1.5s\n",
            "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.941, total=   1.6s\n",
            "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
            "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.936, total=   1.5s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.941, total=   1.8s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.943, total=   1.8s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.941, total=   1.8s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.948, total=   1.8s\n",
            "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
            "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.944, total=   1.7s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.970, total=   4.5s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.962, total=   4.7s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.969, total=   4.4s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.968, total=   4.7s\n",
            "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
            "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.972, total=   3.4s\n",
            "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.577, total=   4.4s\n",
            "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.583, total=   4.0s\n",
            "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.569, total=   4.2s\n",
            "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.565, total=   4.1s\n",
            "[CV] C=100, gamma=1, kernel=sigmoid ..................................\n",
            "[CV] ...... C=100, gamma=1, kernel=sigmoid, score=0.567, total=   4.4s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ....... C=100, gamma=1, kernel=linear, score=0.941, total=   9.5s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ....... C=100, gamma=1, kernel=linear, score=0.943, total=  10.2s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ....... C=100, gamma=1, kernel=linear, score=0.941, total=  10.6s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ....... C=100, gamma=1, kernel=linear, score=0.948, total=  10.2s\n",
            "[CV] C=100, gamma=1, kernel=linear ...................................\n",
            "[CV] ....... C=100, gamma=1, kernel=linear, score=0.944, total=   9.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.964, total=   0.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.970, total=   0.9s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.971, total=   0.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.967, total=   0.8s\n",
            "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
            "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.970, total=   0.8s\n",
            "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.885, total=   1.0s\n",
            "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.900, total=   1.0s\n",
            "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.892, total=   1.0s\n",
            "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.892, total=   0.9s\n",
            "[CV] C=100, gamma=0.1, kernel=sigmoid ................................\n",
            "[CV] .... C=100, gamma=0.1, kernel=sigmoid, score=0.878, total=   0.9s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.941, total=   9.5s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.943, total=   9.8s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.941, total=  10.6s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.948, total=  10.3s\n",
            "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
            "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.944, total=   9.7s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.955, total=   0.9s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.959, total=   1.0s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.960, total=   0.9s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.961, total=   0.9s\n",
            "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
            "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.960, total=   0.9s\n",
            "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
            "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.921, total=   0.4s\n",
            "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
            "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.934, total=   0.4s\n",
            "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
            "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.935, total=   0.4s\n",
            "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
            "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.938, total=   0.4s\n",
            "[CV] C=100, gamma=0.01, kernel=sigmoid ...............................\n",
            "[CV] ... C=100, gamma=0.01, kernel=sigmoid, score=0.934, total=   0.3s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.941, total=   9.3s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.943, total=   9.7s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.941, total=  10.3s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.948, total=   9.8s\n",
            "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
            "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.944, total=   9.4s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.943, total=   0.7s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.946, total=   0.7s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.947, total=   0.7s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.950, total=   0.7s\n",
            "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
            "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.944, total=   0.7s\n",
            "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.941, total=   0.7s\n",
            "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.944, total=   0.7s\n",
            "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.942, total=   0.7s\n",
            "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.945, total=   0.7s\n",
            "[CV] C=100, gamma=0.001, kernel=sigmoid ..............................\n",
            "[CV] .. C=100, gamma=0.001, kernel=sigmoid, score=0.943, total=   0.7s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.941, total=   9.7s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.943, total=   9.9s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.941, total=  10.3s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.948, total=  10.0s\n",
            "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
            "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.944, total=   9.6s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.937, total=   0.7s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.942, total=   0.7s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.939, total=   0.7s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.943, total=   0.7s\n",
            "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
            "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.940, total=   0.7s\n",
            "[CV] C=100, gamma=0.0001, kernel=sigmoid .............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=sigmoid, score=0.937, total=   0.8s\n",
            "[CV] C=100, gamma=0.0001, kernel=sigmoid .............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=sigmoid, score=0.942, total=   0.8s\n",
            "[CV] C=100, gamma=0.0001, kernel=sigmoid .............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=sigmoid, score=0.941, total=   0.8s\n",
            "[CV] C=100, gamma=0.0001, kernel=sigmoid .............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=sigmoid, score=0.944, total=   0.8s\n",
            "[CV] C=100, gamma=0.0001, kernel=sigmoid .............................\n",
            "[CV] . C=100, gamma=0.0001, kernel=sigmoid, score=0.940, total=   0.8s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] .. C=100, gamma=0.0001, kernel=linear, score=0.941, total=   9.4s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] .. C=100, gamma=0.0001, kernel=linear, score=0.943, total=   9.7s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] .. C=100, gamma=0.0001, kernel=linear, score=0.941, total=  10.0s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] .. C=100, gamma=0.0001, kernel=linear, score=0.948, total=   9.8s\n",
            "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
            "[CV] .. C=100, gamma=0.0001, kernel=linear, score=0.944, total=   9.5s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.968, total=   4.6s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.963, total=   4.5s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.967, total=   4.5s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.968, total=   4.5s\n",
            "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
            "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.972, total=   4.4s\n",
            "[CV] C=1000, gamma=1, kernel=sigmoid .................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=sigmoid, score=0.577, total=   4.3s\n",
            "[CV] C=1000, gamma=1, kernel=sigmoid .................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=sigmoid, score=0.583, total=   4.1s\n",
            "[CV] C=1000, gamma=1, kernel=sigmoid .................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=sigmoid, score=0.569, total=   4.4s\n",
            "[CV] C=1000, gamma=1, kernel=sigmoid .................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=sigmoid, score=0.565, total=   4.5s\n",
            "[CV] C=1000, gamma=1, kernel=sigmoid .................................\n",
            "[CV] ..... C=1000, gamma=1, kernel=sigmoid, score=0.567, total=   4.4s\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ...... C=1000, gamma=1, kernel=linear, score=0.941, total= 1.3min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ...... C=1000, gamma=1, kernel=linear, score=0.943, total= 1.3min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ...... C=1000, gamma=1, kernel=linear, score=0.941, total= 1.4min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ...... C=1000, gamma=1, kernel=linear, score=0.947, total= 1.3min\n",
            "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
            "[CV] ...... C=1000, gamma=1, kernel=linear, score=0.944, total= 1.3min\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.962, total=   1.2s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.964, total=   1.2s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.969, total=   1.2s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.966, total=   1.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
            "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.968, total=   1.1s\n",
            "[CV] C=1000, gamma=0.1, kernel=sigmoid ...............................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=sigmoid, score=0.885, total=   1.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=sigmoid ...............................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=sigmoid, score=0.900, total=   1.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=sigmoid ...............................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=sigmoid, score=0.892, total=   1.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=sigmoid ...............................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=sigmoid, score=0.892, total=   1.0s\n",
            "[CV] C=1000, gamma=0.1, kernel=sigmoid ...............................\n",
            "[CV] ... C=1000, gamma=0.1, kernel=sigmoid, score=0.878, total=   0.9s\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] .... C=1000, gamma=0.1, kernel=linear, score=0.941, total= 1.2min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] .... C=1000, gamma=0.1, kernel=linear, score=0.943, total= 1.3min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] .... C=1000, gamma=0.1, kernel=linear, score=0.941, total= 1.4min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] .... C=1000, gamma=0.1, kernel=linear, score=0.947, total= 1.3min\n",
            "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
            "[CV] .... C=1000, gamma=0.1, kernel=linear, score=0.944, total= 1.3min\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.958, total=   2.1s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.967, total=   2.1s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.965, total=   2.0s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.961, total=   2.0s\n",
            "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
            "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.966, total=   2.0s\n",
            "[CV] C=1000, gamma=0.01, kernel=sigmoid ..............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=sigmoid, score=0.922, total=   0.3s\n",
            "[CV] C=1000, gamma=0.01, kernel=sigmoid ..............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=sigmoid, score=0.935, total=   0.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=sigmoid ..............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=sigmoid, score=0.934, total=   0.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=sigmoid ..............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=sigmoid, score=0.937, total=   0.3s\n",
            "[CV] C=1000, gamma=0.01, kernel=sigmoid ..............................\n",
            "[CV] .. C=1000, gamma=0.01, kernel=sigmoid, score=0.935, total=   0.4s\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] ... C=1000, gamma=0.01, kernel=linear, score=0.941, total= 1.2min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] ... C=1000, gamma=0.01, kernel=linear, score=0.943, total= 1.3min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] ... C=1000, gamma=0.01, kernel=linear, score=0.941, total= 1.4min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] ... C=1000, gamma=0.01, kernel=linear, score=0.947, total= 1.3min\n",
            "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
            "[CV] ... C=1000, gamma=0.01, kernel=linear, score=0.944, total= 1.2min\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.952, total=   0.9s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.953, total=   1.1s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.954, total=   1.0s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.957, total=   1.0s\n",
            "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
            "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.951, total=   1.0s\n",
            "[CV] C=1000, gamma=0.001, kernel=sigmoid .............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=sigmoid, score=0.941, total=   0.8s\n",
            "[CV] C=1000, gamma=0.001, kernel=sigmoid .............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=sigmoid, score=0.943, total=   0.9s\n",
            "[CV] C=1000, gamma=0.001, kernel=sigmoid .............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=sigmoid, score=0.941, total=   0.9s\n",
            "[CV] C=1000, gamma=0.001, kernel=sigmoid .............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=sigmoid, score=0.947, total=   0.9s\n",
            "[CV] C=1000, gamma=0.001, kernel=sigmoid .............................\n",
            "[CV] . C=1000, gamma=0.001, kernel=sigmoid, score=0.944, total=   0.9s\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] .. C=1000, gamma=0.001, kernel=linear, score=0.941, total= 1.2min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] .. C=1000, gamma=0.001, kernel=linear, score=0.943, total= 1.2min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] .. C=1000, gamma=0.001, kernel=linear, score=0.941, total= 1.4min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] .. C=1000, gamma=0.001, kernel=linear, score=0.947, total= 1.3min\n",
            "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
            "[CV] .. C=1000, gamma=0.001, kernel=linear, score=0.944, total= 1.2min\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.941, total=   0.6s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.944, total=   0.7s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.942, total=   0.6s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.947, total=   0.7s\n",
            "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
            "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.943, total=   0.6s\n",
            "[CV] C=1000, gamma=0.0001, kernel=sigmoid ............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=sigmoid, score=0.941, total=   0.6s\n",
            "[CV] C=1000, gamma=0.0001, kernel=sigmoid ............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=sigmoid, score=0.944, total=   0.6s\n",
            "[CV] C=1000, gamma=0.0001, kernel=sigmoid ............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=sigmoid, score=0.942, total=   0.6s\n",
            "[CV] C=1000, gamma=0.0001, kernel=sigmoid ............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=sigmoid, score=0.945, total=   0.6s\n",
            "[CV] C=1000, gamma=0.0001, kernel=sigmoid ............................\n",
            "[CV]  C=1000, gamma=0.0001, kernel=sigmoid, score=0.943, total=   0.7s\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV] . C=1000, gamma=0.0001, kernel=linear, score=0.941, total= 1.2min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV] . C=1000, gamma=0.0001, kernel=linear, score=0.943, total= 1.3min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV] . C=1000, gamma=0.0001, kernel=linear, score=0.941, total= 1.4min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV] . C=1000, gamma=0.0001, kernel=linear, score=0.947, total= 1.3min\n",
            "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
            "[CV] . C=1000, gamma=0.0001, kernel=linear, score=0.944, total= 1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done 375 out of 375 | elapsed: 45.3min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['rbf', 'sigmoid', 'linear']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wscwA_Sy2KdO",
        "outputId": "f2af3877-9602-4b87-b8b8-43df37912f4b"
      },
      "source": [
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtyZdcf5EMU7"
      },
      "source": [
        "filename2 = 'finalized_model_svm.sav'\n",
        "pickle.dump(svm1, open(filename2, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DbhBnxhEMu3",
        "outputId": "95cea2d5-497b-4f73-9c7f-43e8e608518f"
      },
      "source": [
        "loaded_model = pickle.load(open(filename2, 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.970276008492569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRG1QvZOzrH0"
      },
      "source": [
        "**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bidHPo5u4qqI"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt1 = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
        "                       max_depth=20, max_features=None, max_leaf_nodes=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=5, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
        "                       random_state=42, splitter='best')\n",
        "dt1.fit(X_train, y_train.ravel())\n",
        "y_pred_dt = dt1.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_ALKJ3q0MqC",
        "outputId": "7661c201-dfc3-4b01-ac6d-00936b5c311a"
      },
      "source": [
        "# Predictions and Evaluations \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred_dt))\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1140   51]\n",
            " [  42 1122]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96      1191\n",
            "           1       0.96      0.96      0.96      1164\n",
            "\n",
            "    accuracy                           0.96      2355\n",
            "   macro avg       0.96      0.96      0.96      2355\n",
            "weighted avg       0.96      0.96      0.96      2355\n",
            "\n",
            "Accuracy: 0.9605095541401274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGd00-yt6wEU",
        "outputId": "8fd7773b-d653-4b06-d166-9b9e848a1781"
      },
      "source": [
        "score_dt = round(accuracy_score(y_pred_dt,y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using DT is: \"+str(score_dt)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using DT is: 96.05 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7sHufBX23hb",
        "outputId": "144da2ee-ca20-4319-8a6a-6b8f391adc00"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {\n",
        "    'max_depth': [2, 3, 5, 10, 20],\n",
        "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
        "    'criterion': [\"gini\", \"entropy\"]\n",
        "}\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), \n",
        "                           param_grid=params, \n",
        "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    3.0s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=4, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=42,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [2, 3, 5, 10, 20],\n",
              "                         'min_samples_leaf': [5, 10, 20, 50, 100]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4iGwCli3UO7",
        "outputId": "42f7d969-bfae-4b9e-9656-21c4efc93ded"
      },
      "source": [
        "# print best parameter after tuning\n",
        "print(grid_search.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid_search.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 5}\n",
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
            "                       max_depth=20, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=5, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=42, splitter='best')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTrLQnyfE751"
      },
      "source": [
        "# save the model to disk\n",
        "filename3 = 'finalized_model_dt.sav'\n",
        "pickle.dump(dt1, open(filename3, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSHLSQPxFHfc",
        "outputId": "24c61ca3-ac24-4810-8d8e-a9bca88111d3"
      },
      "source": [
        "loaded_model = pickle.load(open(filename3, 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9605095541401274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tmZUhAfBoTM"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldHkeJTcBrNd"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf1 = RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=50, max_features=5,\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
        "                       oob_score=False, random_state=None, verbose=0,\n",
        "                       warm_start=False)\n",
        "rf1.fit(X_train, y_train.ravel())\n",
        "y_pred_rf = rf1.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-Uohai2CHMC",
        "outputId": "4d981de0-06f5-4adf-e551-7d296b362a90"
      },
      "source": [
        "# Predictions and Evaluations \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1146   45]\n",
            " [  28 1136]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97      1191\n",
            "           1       0.96      0.98      0.97      1164\n",
            "\n",
            "    accuracy                           0.97      2355\n",
            "   macro avg       0.97      0.97      0.97      2355\n",
            "weighted avg       0.97      0.97      0.97      2355\n",
            "\n",
            "Accuracy: 0.9690021231422505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EaWNldcCdbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "759dfc44-b028-4cce-83fa-a20d42e96c8c"
      },
      "source": [
        "score_rf = round(accuracy_score(y_pred_rf,y_test)*100,2)\n",
        "\n",
        "print(\"The accuracy score achieved using RF is: \"+str(score_rf)+\" %\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy score achieved using RF is: 96.9 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuV8i1aE4H_5",
        "outputId": "b03220cc-1751-4d1f-b27f-b2e1b608261f"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "{'n_estimators': [10, 25], 'max_features': [5, 10], \n",
        " 'max_depth': [10, 50, None], 'bootstrap': [True, False]}\n",
        "]\n",
        "\n",
        "grid_search_forest = GridSearchCV(RandomForestClassifier(n_jobs=-1), param_grid, cv=10, scoring='neg_mean_squared_error')\n",
        "grid_search_forest.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=-1,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'bootstrap': [True, False],\n",
              "                          'max_depth': [10, 50, None], 'max_features': [5, 10],\n",
              "                          'n_estimators': [10, 25]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eefm9lPH5BTk",
        "outputId": "3ac23675-38fc-4701-85a0-6ac1ec40c572"
      },
      "source": [
        "# print best parameter after tuning\n",
        "print(grid_search_forest.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid_search_forest.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bootstrap': False, 'max_depth': 50, 'max_features': 5, 'n_estimators': 10}\n",
            "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=50, max_features=5,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
            "                       oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8eLvmFxFrLU"
      },
      "source": [
        "# save the model to disk\n",
        "filename4 = 'finalized_model_rf.sav'\n",
        "pickle.dump(rf1, open(filename4, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqYSL33tF8I3",
        "outputId": "9b994acc-6ba8-42b9-8d41-85d069cf1aa3"
      },
      "source": [
        "loaded_model = pickle.load(open(filename4, 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9690021231422505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvMFYUQjdl9H"
      },
      "source": [
        "**Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCEKom3xfgqq"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGE10I3oTB-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "0aadea53-789a-4682-d039-30be920bc48c"
      },
      "source": [
        "#scores = [score_knn,score_svm,score_ANN]\n",
        "#algorithms = [\"K-Nearest Neighbors\",\"Support Vector Machines\",\"ANN\",\"ImpactLearning\"] \n",
        "scores = [score_ANN,score_lr,score_knn,score_svm,score_dt]\n",
        "algorithms = [\"Artficial Neural Network\",\"Logistic Regression\",\"K-Nearest Neighbors\",\"Support Vector Machines\",\"Decision Tree\"]\n",
        "sns.set(rc={'figure.figsize':(15,6)})\n",
        "plt.xlabel(\"Algorithms\")\n",
        "plt.ylabel(\"Accuracy score\")\n",
        "\n",
        "sns.barplot(algorithms,scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff97221fdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}