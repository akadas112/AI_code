{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYe9x_DcmAd8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVjYeLhanqPa"
      },
      "source": [
        "#Importing important files....\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "from xgboost import XGBRegressor, plot_tree\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.inspection import permutation_importance\n",
        "from statistics import mean\n",
        "from sklearn import tree\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pickle\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU9HjvZJnqM0"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Dataset/Parkinson disease.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d5GwOI9nqIK"
      },
      "source": [
        "df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl7VaefDnqGC"
      },
      "source": [
        "_#Defining features(X) and labels(Y)....\n",
        "X = df.drop(['status','name'],axis =1).values\n",
        "y = df['status'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YfY8GPqnqDi"
      },
      "source": [
        "X = pd.DataFrame(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1WKclgOnqBK"
      },
      "source": [
        "#Checking is any nan value available or not\n",
        "np.any(np.isnan(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3GqjZWJnp_D"
      },
      "source": [
        "#Missing value handle\n",
        "imputer = SimpleImputer(missing_values = np.NaN, strategy = 'mean')\n",
        "imputer = imputer.fit(X)\n",
        "X = imputer.transform(X)\n",
        "final_dataset = pd.DataFrame(X)\n",
        "final_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc3_G7Cbnp8a"
      },
      "source": [
        "#Feature scaling\n",
        "feature_X = StandardScaler().fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNDoZlifnp56"
      },
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y == 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xUxkeeWnp3i"
      },
      "source": [
        "#over sampling\n",
        "sm = SMOTE(random_state = 2)\n",
        "X_res, y_res = sm.fit_sample(feature_X, y.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res == 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNrMs_Y8np0y"
      },
      "source": [
        "#Tr=list()\n",
        "#Te=list()\n",
        "##mse=list()\n",
        "#rmse=list()\n",
        "#pr=list()\n",
        "#re=list()\n",
        "#f=list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6du2JPDwnpya"
      },
      "source": [
        "#Train and test data set split.....\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAxmEPQ7npwD"
      },
      "source": [
        "model_ada =AdaBoostClassifier(algorithm='SAMME.R',\n",
        "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
        "                                                         class_weight=None,\n",
        "                                                         criterion='gini',\n",
        "                                                         max_depth=4,\n",
        "                                                         max_features=None,\n",
        "                                                         max_leaf_nodes=None,\n",
        "                                                         min_impurity_decrease=0.0,\n",
        "                                                         min_impurity_split=None,\n",
        "                                                         min_samples_leaf=5,\n",
        "                                                         min_samples_split=2,\n",
        "                                                         min_weight_fraction_leaf=0.0,\n",
        "                                                         presort='deprecated',\n",
        "                                                         random_state=None,\n",
        "                                                         splitter='best'),\n",
        "                   learning_rate=0.01, n_estimators=1000, random_state=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPEkK_9ynptU"
      },
      "source": [
        "#Fitting the defined model\n",
        "model_ada.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j91J3lyQnpq6"
      },
      "source": [
        "#Prediction\n",
        "y_pred = model_ada.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nOkawd0npoa"
      },
      "source": [
        "model_ada.score(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AARIZSKDnpmL"
      },
      "source": [
        "#Model score\n",
        "model_ada.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XEOwadXnpj0"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.heatmap(cm, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaOv6aPrnphi"
      },
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3zpyNWAnpfL"
      },
      "source": [
        "#Precision,recall,f1_score,cohen_kappa_score,auc.......\n",
        "print(\"Precision,recall,f1 score,cohen kappa score,auc.....\")\n",
        "print(\" \")\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test,y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test,  y_pred)\n",
        "print('ROC AUC: %f' % auc)\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9FscUJ_npcy"
      },
      "source": [
        "Tr.append(model_ada.score(X_train,y_train))\n",
        "Te.append(model_ada.score(X_test,y_test))\n",
        "mse.append(metrics.mean_squared_error(y_test, y_pred))\n",
        "rmse.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "pr.append(precision_score(y_test, y_pred))\n",
        "re.append(recall_score(y_test,y_pred))\n",
        "f.append(f1_score(y_test, y_pred))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pm7VJCqnpaa"
      },
      "source": [
        "print(Tr)\n",
        "print(Te)\n",
        "print(mse)\n",
        "print(rmse)\n",
        "print(pr)\n",
        "print(re)\n",
        "print(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naOTDP5TnpYS"
      },
      "source": [
        "features = range(1,8)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(features, Tr, 'g', label='Training accuraccy')\n",
        "plt.plot(features, Te, 'b', label='Test accuraccy')\n",
        "plt.title(' Accuracy vs Feature Number(AdaBoost)')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('ADA_accuraccy_vs_features.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ3wgtTknpKJ"
      },
      "source": [
        "features = range(1,8)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(features, mse, 'red', label='Loss(MSE and MAE )')\n",
        "plt.plot(features,rmse, 'orange', label='Loss(RMSE)')\n",
        "plt.title(' Model Loss vs Features(AdaBoost)')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Model Loss')\n",
        "plt.legend()\n",
        "plt.savefig('ADA_loss_vs_features.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlBaFA61npHq"
      },
      "source": [
        "\n",
        "pickle.dump(model_ada, open(\"model_ada_last_1.pkl\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PP7x7wdwU96"
      },
      "source": [
        "import pickle\n",
        "model = pickle.load(open(\"model_ada_last_1.pkl\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuWWzoL-wag8"
      },
      "source": [
        "model.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}