{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akadas112/AI_code/blob/main/Questionaries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoEQJCmni5iJ"
      },
      "source": [
        "Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P9qV_5HSM3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfda63fb-5a15-494c-9670-df0b250f32f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WncCK22Qi9vQ"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU3hnVdg5m20"
      },
      "outputs": [],
      "source": [
        "#Importing important files....\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "from xgboost import XGBRegressor, plot_tree\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.inspection import permutation_importance\n",
        "from statistics import mean\n",
        "from sklearn import tree\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWX4yneUjPXL"
      },
      "source": [
        "Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "Ojmk2mcs5pns",
        "outputId": "ffeb96fe-1926-4e19-9995-e42d6787cdab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-63f975239f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Parkinson all docs/Dataset/combine dataset(train).xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Parkinson all docs/Dataset/combine dataset(test).xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 ext = inspect_excel_format(\n\u001b[0;32m-> 1192\u001b[0;31m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1193\u001b[0m                 )\n\u001b[1;32m   1194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     with get_handle(\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     ) as handle:\n\u001b[1;32m   1073\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Parkinson all docs/Dataset/combine dataset(train).xlsx'"
          ]
        }
      ],
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/Parkinson all docs/Dataset/combine dataset(train).xlsx')\n",
        "df_test=pd.read_excel('/content/drive/MyDrive/Parkinson all docs/Dataset/combine dataset(test).xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOyNxAc1G3vH"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBvXqQ0qjSBy"
      },
      "source": [
        "Visualizing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hd09y9p_Vc3"
      },
      "outputs": [],
      "source": [
        "# plot histograms for each variable\n",
        "df.hist(figsize = (30, 30))\n",
        "# show the plot\n",
        "plt.savefig('Histogram.png')\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-jO_LgWjV1g"
      },
      "source": [
        "Separate data and target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPjJouCo5uH9"
      },
      "outputs": [],
      "source": [
        "_#Defining features(X) and labels(Y)....\n",
        "X_train = df.drop(['Status','PAT_NO','Event_ID'],axis =1).values\n",
        "y_train = df['Status'].values\n",
        "X_test = df_test.drop(['Status','PAT_NO','Event_ID'],axis =1).values\n",
        "y_test = df_test['Status'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ1GZch6PVUa"
      },
      "outputs": [],
      "source": [
        "#Healthy amd pd patient count\n",
        "sns.countplot(df['Status'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbJEqpGjP6Gh"
      },
      "outputs": [],
      "source": [
        "df['Status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e_KQ0sAHb79"
      },
      "outputs": [],
      "source": [
        "df_test['Status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYP_MzbBjdLl"
      },
      "source": [
        "Missing Value Handle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FC5w7nkKrsU"
      },
      "outputs": [],
      "source": [
        "#Checking is any nan value available or not\n",
        "np.any(np.isnan(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM8UFmvvKjdY"
      },
      "outputs": [],
      "source": [
        "#Missing value handle\n",
        "imputer = SimpleImputer(missing_values = np.NaN, strategy = 'mean')\n",
        "imputer = imputer.fit(X_train)\n",
        "X_train = imputer.transform(X_train)\n",
        "imputer1 = SimpleImputer(missing_values = np.NaN, strategy = 'mean')\n",
        "imputer1 = imputer1.fit(X_test)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL_cZMmSH58L"
      },
      "outputs": [],
      "source": [
        "#Checking is any nan value available or not\n",
        "np.any(np.isnan(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7iDa8pROF9N"
      },
      "source": [
        "Feature scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Zf3XOI5yA1Z"
      },
      "outputs": [],
      "source": [
        "##from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# fit scaler on training data\n",
        "#norm = MinMaxScaler().fit(X_train)\n",
        "\n",
        "# transform training data\n",
        "#X_train = norm.transform(X_train)\n",
        "\n",
        "# transform testing dataabs\n",
        "#X_test = norm.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkBdqylfw72g"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "X_test = StandardScaler().fit_transform(X_test)\n",
        "\n",
        "feature_X_train = pd.DataFrame(X_train) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw7vys5zHV4N"
      },
      "outputs": [],
      "source": [
        "feature_X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYTonr2QPeqn"
      },
      "source": [
        "Rank sum test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExRup_Pj_wBK"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ranksums\n",
        "scipy.stats.ranksums(X_train[:2943,:1] ,X_train[2943:,:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_OdXcOnjhur"
      },
      "source": [
        "Features co-relation heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4bPtxGVJ-t1"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(40,40))\n",
        "sns.heatmap(feature_X_train.corr(), center=0, cmap='Blues',annot=True)\n",
        "ax.set_title('Multi-Collinearity of Parkinson Symptoms')\n",
        "# show the plot\n",
        "plt.savefig('Heatmap.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD9USFXtjytf"
      },
      "source": [
        "Oversampling(for Balancing data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtTeg_NdxC_D"
      },
      "outputs": [],
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBDFbi77xM_e"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 2)\n",
        "X_res, y_res = sm.fit_resample(X_train, y_train.ravel())\n",
        "  \n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape))\n",
        "  \n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res == 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDSwIJ14HYAm"
      },
      "outputs": [],
      "source": [
        "np.any(np.isnan(X_train))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f4VS9YvQc7m"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5XiuNnlQdUv"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aALw6Ycl5woG"
      },
      "outputs": [],
      "source": [
        "#Preview of Train and test data....\n",
        "print(\"Train Dataset:\")\n",
        "\n",
        "print(\"Training features: \")\n",
        "print(\" \")\n",
        "print(X_train)\n",
        "print(\" \")\n",
        "\n",
        "print(\"Training labels: \")\n",
        "print(\" \")\n",
        "print(y_train)\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "\n",
        "\n",
        "print(\"Test Dataset:\")\n",
        "\n",
        "print(\"Testing features: \")\n",
        "print(\" \")\n",
        "print(X_test)\n",
        "print(\" \")\n",
        "\n",
        "print(\"Testing labels: \")\n",
        "print(\" \")\n",
        "print(y_test)\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggWz7LUyXE72"
      },
      "source": [
        "**LR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uSKw2BQ5xWH"
      },
      "outputs": [],
      "source": [
        "#Definimng  LR model\n",
        "model = LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
        "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
        "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
        "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                   warm_start=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzdDMuCK5z1x"
      },
      "outputs": [],
      "source": [
        "#Fitting the defined model\n",
        "model.fit(X_res, y_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJTOq7Quj9QV"
      },
      "source": [
        "Permutation importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcGGIc13OxXb"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "%matplotlib inline\n",
        "\n",
        "feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10,random_state=0)\n",
        "\n",
        "features_names = ['0', '1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52']\n",
        "features = np.array(features_names)\n",
        "\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "\n",
        "plt.figure(figsize=(20, 14))\n",
        "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")\n",
        "\n",
        "variable=list()\n",
        "variable_droped=list()\n",
        "#Features importance before applying treshold......\n",
        "print('Features importance before applying threshold(mean)......')  \n",
        "\n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t  print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t \n",
        "\n",
        "#Features importance after applying treshold......\t \n",
        "print('\\n\\nFeatures importance after applying threshold(mean): %.5f\\n'%mean(perm_importance.importances_mean))  \n",
        "\t \n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t\n",
        " \n",
        "\tif(v>=mean(perm_importance.importances_mean)):\n",
        "    \n",
        "\t  #print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t\tvariable.append(i)\n",
        "\telse:\n",
        "\t\tvariable_droped.append(i)\n",
        "\n",
        "   \n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "#print('Threshold(Means of importances): %.5f' %mean(perm_importance.importances_mean))\n",
        "count=-1\n",
        "for i in variable:\n",
        "\tcount+=1\n",
        "\tprint('Feature no after thresholding:%s   ' %count + 'Feature no in main dataset:%s   ' % str(i) + 'Feature Name:%s   ' %feature_names[i] + 'Feature importance: %s' %perm_importance.importances_mean[i])\n",
        "print(variable) \n",
        "print(variable_droped) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfEgfXtWU1E2"
      },
      "outputs": [],
      "source": [
        " import time\n",
        "t0=time.time()\n",
        "model.fit(X_res, y_res)\n",
        "print (\"training time:\", round(time.time()-t0, 3), \"s\") # the time would be round to 3 decimal in seconds\n",
        "t1=time.time()\n",
        "y_pred = model.predict(X_test)\n",
        "print (\"predict time:\", round(time.time()-t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au51R0Uh52bT"
      },
      "outputs": [],
      "source": [
        "#Prediction\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp88T8tzmccu"
      },
      "outputs": [],
      "source": [
        "model.score(X_res,y_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Srrar8V952-E"
      },
      "outputs": [],
      "source": [
        "#Model score\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRKTtWeWZZwf"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(model, open(\"model_LR_1.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMl3-6HgZfvp"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "model = pickle.load(open(\"model_LR_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aH4RP2ef8asb"
      },
      "outputs": [],
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test,  y_pred)\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "plt.savefig('LR_all_auc.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O9CkjoY57hm"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UcxmEdh6DcZ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "# show the plot\n",
        "plt.savefig('LR_all_CM.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqTVEb4l1TXj"
      },
      "outputs": [],
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))  \n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))  \n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_0-Bn0H1KJZ"
      },
      "outputs": [],
      "source": [
        "#Precision,recall,f1_score,cohen_kappa_score,auc.......\n",
        "print(\"Precision,recall,f1 score,cohen kappa score,auc.....\")\n",
        "print(\" \")\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test,y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test,  y_pred)\n",
        "print('ROC AUC: %f' % auc)\n",
        "#Cohen's kappa\n",
        "kappa=cohen_kappa_score(y_test,  y_pred)\n",
        "print('Cohen Kappa: %f' % kappa)\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td_GKy5jW8mq"
      },
      "source": [
        " **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8quqP3ZWVoD"
      },
      "outputs": [],
      "source": [
        "#Definimng SVM model\n",
        "model_svm = SVC(C=1000,break_ties=False,cache_size=200,class_weight=None, coef0=0.0,decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',max_iter=-1, probability=False, random_state=None,shrinking=True,tol=0.001,verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hao9eJxWXqT"
      },
      "outputs": [],
      "source": [
        "#Fitting the defined model\n",
        "model_svm.fit(X_res, y_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myHywnUJWX7N"
      },
      "outputs": [],
      "source": [
        "#Prediction\n",
        "y_predicted_svm = model_svm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08wcWimLUn5B"
      },
      "outputs": [],
      "source": [
        " import time\n",
        "t0=time.time()\n",
        "model_svm.fit(X_res, y_res)\n",
        "print (\"training time:\", round(time.time()-t0, 3), \"s\") # the time would be round to 3 decimal in seconds\n",
        "t1=time.time()\n",
        "y_predicted_svm = model_svm.predict(X_test)\n",
        "print (\"predict time:\", round(time.time()-t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbLLN6ZRWYQM"
      },
      "outputs": [],
      "source": [
        "#Model score\n",
        "model_svm.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkmAMALlWYjr"
      },
      "outputs": [],
      "source": [
        "model_svm.score(X_res, y_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn8tDOEmN6KF"
      },
      "outputs": [],
      "source": [
        "print(len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqvrVvnk56_j"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(model_svm, open(\"model_svm_1.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1YP91PC7Xch"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "model = pickle.load(open(\"model_svm_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s64-5ozFWwP_"
      },
      "outputs": [],
      "source": [
        "cm1 = confusion_matrix(y_test, y_predicted_svm)\n",
        "print(cm1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsmHD9YJWwe2"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm1, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "# show the plot\n",
        "plt.savefig('SVM_all_CM.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5qfj9lSXUDl"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "%matplotlib inline\n",
        "\n",
        "feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model_svm, X_test, y_test, n_repeats=10,random_state=0)\n",
        "\n",
        "features_names = ['0', '1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52']\n",
        "features = np.array(features_names)\n",
        "\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "\n",
        "plt.figure(figsize=(20, 14))\n",
        "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")\n",
        "\n",
        "variable=list()\n",
        "variable_droped=list()\n",
        "#Features importance before applying treshold......\n",
        "print('Features importance before applying threshold(mean)......')  \n",
        "\n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t  print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t \n",
        "\n",
        "#Features importance after applying treshold......\t \n",
        "print('\\n\\nFeatures importance after applying threshold(mean): %.5f\\n'%mean(perm_importance.importances_mean))  \n",
        "\t \n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t\n",
        " \n",
        "\tif(v>=mean(perm_importance.importances_mean)):\n",
        "    \n",
        "\t  #print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t\tvariable.append(i)\n",
        "\telse:\n",
        "\t\tvariable_droped.append(i)\n",
        "\n",
        "   \n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "#print('Threshold(Means of importances): %.5f' %mean(perm_importance.importances_mean))\n",
        "count=-1\n",
        "for i in variable:\n",
        "\tcount+=1\n",
        "\tprint('Feature no after thresholding:%s   ' %count + 'Feature no in main dataset:%s   ' % str(i) + 'Feature Name:%s   ' %feature_names[i] + 'Feature importance: %s' %perm_importance.importances_mean[i])\n",
        "print(variable) \n",
        "print(variable_droped) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIpGG5kKy66R"
      },
      "outputs": [],
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, y_predicted_svm))  \n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_predicted_svm))  \n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_predicted_svm)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TIrRX5gzAnN"
      },
      "outputs": [],
      "source": [
        "#Precision,recall,f1_score,cohen_kappa_score,auc.......\n",
        "print(\"Precision,recall,f1 score,cohen kappa score,auc.....\")\n",
        "print(\" \")\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_predicted_svm)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test,y_predicted_svm)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_predicted_svm)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test,  y_predicted_svm)\n",
        "print('ROC AUC: %f' % auc)\n",
        "#Cohen's kappa\n",
        "kappa=cohen_kappa_score(y_test,  y_predicted_svm)\n",
        "print('Cohen Kappa: %f' % kappa)\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-zjbqeSBkVn"
      },
      "outputs": [],
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted_svm)\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='SVM')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "plt.savefig('SVM_all_auc.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfNMF-IYUuAx"
      },
      "source": [
        "Gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARu3Dh93TRyp"
      },
      "outputs": [],
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "#from sklearn.metrics import classification_report, confusion_matrix\n",
        "  \n",
        " #defining parameter range\n",
        "#param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
        "              #'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "             # 'kernel': ['rbf']} \n",
        "  \n",
        "#grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "  \n",
        " #fitting the model for grid search\n",
        "#grid.fit(X_train, y_train)\n",
        "# print best parameter after tuning\n",
        "#print(grid.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "#print(grid.best_estimator_)\n",
        "#grid_predictions = grid.predict(X_test)\n",
        "  \n",
        "# print classification report\n",
        "#print(classification_report(y_test, grid_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0BQQqT8XfsY"
      },
      "source": [
        "**DT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4t1BTIfFXw0Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "#Definimng model\n",
        "model_dt = DecisionTreeClassifier(ccp_alpha=0.0,class_weight=None,criterion='entropy',max_depth=None, max_features=10, max_leaf_nodes=None,\n",
        "min_impurity_decrease=0.0,\n",
        "min_samples_leaf=6,min_samples_split=2,min_weight_fraction_leaf=0.0,random_state=None, splitter='best'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY5nzuJHX0zx"
      },
      "outputs": [],
      "source": [
        "#Fitting the defined model\n",
        "#model_dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5nVPIb5aqE0"
      },
      "outputs": [],
      "source": [
        " import time\n",
        "t0=time.time()\n",
        "model_dt.fit(X_res, y_res)\n",
        "print (\"training time:\", round(time.time()-t0, 3), \"s\") # the time would be round to 3 decimal in seconds\n",
        "t1=time.time()\n",
        "y_predicted_dt = model_dt.predict(X_test)\n",
        "print (\"predict time:\", round(time.time()-t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oLHJ8hFPG0h"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "%matplotlib inline\n",
        "\n",
        "feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model_dt, X_test, y_test, n_repeats=10,random_state=0)\n",
        "\n",
        "features_names = ['0', '1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52']\n",
        "features = np.array(features_names)\n",
        "\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "\n",
        "plt.figure(figsize=(20, 14))\n",
        "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")\n",
        "\n",
        "variable=list()\n",
        "variable_droped=list()\n",
        "#Features importance before applying treshold......\n",
        "print('Features importance before applying threshold(mean)......')  \n",
        "\n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t  print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t \n",
        "\n",
        "#Features importance after applying treshold......\t \n",
        "print('\\n\\nFeatures importance after applying threshold(mean): %.5f\\n'%mean(perm_importance.importances_mean))  \n",
        "\t \n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t\n",
        " \n",
        "\tif(v>=mean(perm_importance.importances_mean)):\n",
        "    \n",
        "\t  #print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t\tvariable.append(i)\n",
        "\telse:\n",
        "\t\tvariable_droped.append(i)\n",
        "\n",
        "   \n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "#print('Threshold(Means of importances): %.5f' %mean(perm_importance.importances_mean))\n",
        "count=-1\n",
        "for i in variable:\n",
        "\tcount+=1\n",
        "\tprint('Feature no after thresholding:%s   ' %count + 'Feature no in main dataset:%s   ' % str(i) + 'Feature Name:%s   ' %feature_names[i] + 'Feature importance: %s' %perm_importance.importances_mean[i])\n",
        "print(variable) \n",
        "print(variable_droped) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2Aqdv7RYRPU"
      },
      "outputs": [],
      "source": [
        "#Prediction\n",
        "#y_predicted_dt = model_dt.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FQOmk8rX7ID"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_predicted_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi9lCoPGlA5z"
      },
      "outputs": [],
      "source": [
        "model_dt.score(X_res, y_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzBK9wizcbUO"
      },
      "outputs": [],
      "source": [
        "# use model to predict\n",
        "model_dt.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7OvWh1C7yxE"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(model_dt, open(\"model_DT_1.pkl\", \"wb\"))\n",
        "# load the model\n",
        "model = pickle.load(open(\"model_DT_1.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Mkf47TN72r1"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "model = pickle.load(open(\"model_DT_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBsjrHraX7pM"
      },
      "outputs": [],
      "source": [
        "cm2 = confusion_matrix(y_test, y_predicted_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF43WPOJX74s"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm2, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "# show the plot\n",
        "plt.savefig('DT_all_CM.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iiwlqnt3BOeO"
      },
      "outputs": [],
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted_svm)\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='DT')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "plt.savefig('DT_auc.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAKnBk53s7sq"
      },
      "outputs": [],
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, y_predicted_dt))  \n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_predicted_dt))  \n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_predicted_dt)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhMuu5P6tA8z"
      },
      "outputs": [],
      "source": [
        "#Precision,recall,f1_score,cohen_kappa_score,auc.......\n",
        "print(\"Precision,recall,f1 score,cohen kappa score,auc.....\")\n",
        "print(\" \")\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_predicted_dt)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test,y_predicted_dt)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_predicted_dt)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test,  y_predicted_dt)\n",
        "print('ROC AUC: %f' % auc)\n",
        "#Cohen's kappa\n",
        "kappa=cohen_kappa_score(y_test,  y_predicted_dt)\n",
        "print('Cohen Kappa: %f' % kappa)\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG5wXPlCoGkU"
      },
      "outputs": [],
      "source": [
        "feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "from six import StringIO\n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "dot_data = StringIO()\n",
        "export_graphviz(model_dt, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, feature_names = feature_names,class_names=['0','1'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('Parkinson_DT_image.png')\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHn2wOKLUop_"
      },
      "source": [
        "RandomizedSearch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Fkk9mWfUNOU"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import randint\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Creating the hyperparameter grid \n",
        "param_dist = {\"max_depth\": [3, None],\n",
        "              \"max_features\": randint(1, 9),\n",
        "              \"min_samples_leaf\": randint(1, 9),\n",
        "              \"criterion\": [\"gini\", \"entropy\"]}\n",
        "  \n",
        "# Instantiating Decision Tree classifier\n",
        "tree = DecisionTreeClassifier()\n",
        "  \n",
        "# Instantiating RandomizedSearchCV object\n",
        "tree_cv = RandomizedSearchCV(tree, param_dist, cv = 500)\n",
        "  \n",
        "tree_cv.fit(X_train, y_train)\n",
        "  \n",
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
        "print(\"Best score is {}\".format(tree_cv.best_score_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY6IeDftZYQa"
      },
      "source": [
        "RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFLBRgkRZWvr"
      },
      "outputs": [],
      "source": [
        "#Definimng model\n",
        "model_rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=4, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh_IBkXDZbJC"
      },
      "outputs": [],
      "source": [
        "#Fitting the defined model\n",
        "#model_rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QscpwVIffN4"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "t0=time.time()\n",
        "model_rf.fit(X_res, y_res)\n",
        "print (\"training time:\", round(time.time()-t0, 3), \"s\") # the time would be round to 3 decimal in seconds\n",
        "t1=time.time()\n",
        "y_predicted_rf = model_rf.predict(X_test)\n",
        "print (\"predict time:\", round(time.time()-t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzQXAuhNpTUn"
      },
      "outputs": [],
      "source": [
        "model_rf_1 = pickle.load(open(\"model_RF_1.pkl\", \"rb\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1zzWeWFPheU"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "%matplotlib inline\n",
        "\n",
        "feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model_rf_1, X_test, y_test, n_repeats=10,random_state=0)\n",
        "\n",
        "features_names = ['0', '1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52']\n",
        "features = np.array(features_names)\n",
        "\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "\n",
        "plt.figure(figsize=(20, 14))\n",
        "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")\n",
        "\n",
        "variable=list()\n",
        "variable_droped=list()\n",
        "#Features importance before applying treshold......\n",
        "print('Features importance before applying threshold(mean)......')  \n",
        "\n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t  print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t \n",
        "\n",
        "#Features importance after applying treshold......\t \n",
        "print('\\n\\nFeatures importance after applying threshold(mean): %.5f\\n'%mean(perm_importance.importances_mean))  \n",
        "\t \n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t\n",
        " \n",
        "\tif(v>=mean(perm_importance.importances_mean)):\n",
        "    \n",
        "\t  #print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t\tvariable.append(i)\n",
        "\telse:\n",
        "\t\tvariable_droped.append(i)\n",
        "\n",
        "   \n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "#print('Threshold(Means of importances): %.5f' %mean(perm_importance.importances_mean))\n",
        "count=-1\n",
        "for i in variable:\n",
        "\tcount+=1\n",
        "\tprint('Feature no after thresholding:%s   ' %count + 'Feature no in main dataset:%s   ' % str(i) + 'Feature Name:%s   ' %feature_names[i] + 'Feature importance: %s' %perm_importance.importances_mean[i])\n",
        "print(variable) \n",
        "print(variable_droped) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2FwjW5_ZbWi"
      },
      "outputs": [],
      "source": [
        "#Prediction\n",
        "#y_predicted_rf = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw4qTD_QZbl6"
      },
      "outputs": [],
      "source": [
        "#Model score\n",
        "model_rf.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-ryh3fiZb4z"
      },
      "outputs": [],
      "source": [
        "model_rf.score(X_res, y_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsIHgRaRaO2G"
      },
      "outputs": [],
      "source": [
        "pickle.dump(model_rf, open(\"model_RF_1.pkl\", \"wb\"))\n",
        "model = pickle.load(open(\"model_RF_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WixP6iM7ZcT7"
      },
      "outputs": [],
      "source": [
        "cm3 = confusion_matrix(y_test, y_predicted_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fpC7j4WZclz"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm3, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.savefig('RF_all_CM.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DLEwzkXCXj7"
      },
      "outputs": [],
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted_dt)\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='RF')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "plt.savefig('RF_auc.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI6NZXOvyI5Z"
      },
      "outputs": [],
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, y_predicted_rf))  \n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_predicted_rf))  \n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_predicted_rf)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLx0w7q0yY_B"
      },
      "outputs": [],
      "source": [
        "#Precision,recall,f1_score,cohen_kappa_score,auc.......\n",
        "print(\"Precision,recall,f1 score,cohen kappa score,auc.....\")\n",
        "print(\" \")\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_predicted_rf)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test,y_predicted_rf)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_predicted_rf)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test,  y_predicted_rf)\n",
        "print('ROC AUC: %f' % auc)\n",
        "#Cohen's kappa\n",
        "kappa=cohen_kappa_score(y_test,  y_predicted_rf)\n",
        "print('Cohen Kappa: %f' % kappa)\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QL0V2O0CC0qS"
      },
      "outputs": [],
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, y_predicted_dt)\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='RF')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "plt.savefig('RF_auc.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAiQkfvYEPU6"
      },
      "outputs": [],
      "source": [
        "\n",
        "feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
        "tree.plot_tree(model_rf.estimators_[4],\n",
        "               feature_names = feature_names, \n",
        "               class_names=['0','1'],\n",
        "               filled = True);\n",
        "fig.savefig('rf_individualtree_5.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHsdBG5W44fD"
      },
      "source": [
        "**XGB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSb-x69jABwE"
      },
      "outputs": [],
      "source": [
        "# fit model no training data\n",
        "model_XGB = XGBClassifier(ase_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1.0, gamma=1,\n",
        "              learning_rate=0.02, max_delta_step=0, max_depth=4,\n",
        "              min_child_weight=1, missing=None, n_estimators=200, n_jobs=1,\n",
        "              nthread=1, objective='binary:logistic', random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=True, subsample=0.8, verbosity=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCZqrIbrC0-m"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "t0=time.time()\n",
        "model_XGB.fit(X_res, y_res)\n",
        "print (\"training time:\", round(time.time()-t0, 3), \"s\") # the time would be round to 3 decimal in seconds\n",
        "t1=time.time()\n",
        "y_pred_XGB = model_XGB.predict(X_test)\n",
        "print (\"predict time:\", round(time.time()-t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4Z_p2qR3fJo"
      },
      "outputs": [],
      "source": [
        "model_XGB.score(X_res,y_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfWSGqW8ObVv"
      },
      "outputs": [],
      "source": [
        "model_XGB.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoohbI3rLWKX"
      },
      "outputs": [],
      "source": [
        "pickle.dump(model_XGB, open(\"model_XGB_1.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG6x6o5bLf0j"
      },
      "outputs": [],
      "source": [
        "model = pickle.load(open(\"model_XGB_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTpytRNK30TZ"
      },
      "outputs": [],
      "source": [
        "cm3 = confusion_matrix(y_test, y_pred_XGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9R2Dykh39kQ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm3, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "plt.savefig('XGB_all_CM.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31JK0dbI4BgN"
      },
      "outputs": [],
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred_XGB))  \n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred_XGB))  \n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_XGB)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tsalifv84Fw3"
      },
      "outputs": [],
      "source": [
        "#Precision,recall,f1_score,cohen_kappa_score,auc.......\n",
        "print(\"Precision,recall,f1 score,cohen kappa score,auc.....\")\n",
        "print(\" \")\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_pred_XGB)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test,y_pred_XGB)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred_XGB)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test,  y_pred_XGB)\n",
        "print('ROC AUC: %f' % auc)\n",
        "#Cohen's kappa\n",
        "kappa=cohen_kappa_score(y_test,  y_pred_XGB)\n",
        "print('Cohen Kappa: %f' % kappa)\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqXVejJDD4pF"
      },
      "outputs": [],
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, y_pred_XGB)\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='XGB')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "plt.savefig('XGB_all_auc.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFrBIk8NHNWq"
      },
      "outputs": [],
      "source": [
        "model_XGB_1 = pickle.load(open(\"model_XGB_1.pkl\", \"rb\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZdPm7R84YjG"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "%matplotlib inline\n",
        "\n",
        "feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model_XGB_1, X_test, y_test, n_repeats=10,random_state=0)\n",
        "\n",
        "features_names = ['0', '1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52']\n",
        "features = np.array(features_names)\n",
        "\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "\n",
        "plt.figure(figsize=(20, 14))\n",
        "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")\n",
        "\n",
        "variable=list()\n",
        "variable_droped=list()\n",
        "#Features importance before applying treshold......\n",
        "print('Features importance before applying threshold(mean)......')  \n",
        "\n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t  print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t \n",
        "\n",
        "#Features importance after applying treshold......\t \n",
        "print('\\n\\nFeatures importance after applying threshold(mean): %.5f\\n'%mean(perm_importance.importances_mean))  \n",
        "\t \n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t\n",
        " \n",
        "\tif(v>=mean(perm_importance.importances_mean)):\n",
        "    \n",
        "\t  #print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t\tvariable.append(i)\n",
        "\telse:\n",
        "\t\tvariable_droped.append(i)\n",
        "\n",
        "   \n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "#print('Threshold(Means of importances): %.5f' %mean(perm_importance.importances_mean))\n",
        "count=-1\n",
        "for i in variable:\n",
        "\tcount+=1\n",
        "\tprint('Feature no after thresholding:%s   ' %count + 'Feature no in main dataset:%s   ' % str(i) + 'Feature Name:%s   ' %feature_names[i] + 'Feature importance: %s' %perm_importance.importances_mean[i])\n",
        "print(variable) \n",
        "print(variable_droped) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKOUG7Kb8mF0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(model_XGB, open(\"model_XGB_1.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdcFuIU58rHD"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "model = pickle.load(open(\"model_XGB_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rflkog3ZAsT"
      },
      "source": [
        "KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bs14XooJOecI"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model_KNN = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
        "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
        "                     weights='uniform')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3RALH9zDNXN"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "t0=time.time()\n",
        "model_KNN.fit(X_res, y_res)\n",
        "print (\"training time:\", round(time.time()-t0, 3), \"s\") # the time would be round to 3 decimal in seconds\n",
        "t1=time.time()\n",
        "y_pred_KNN = model_KNN.predict(X_test)\n",
        "print (\"predict time:\", round(time.time()-t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SCYYqjxhocb"
      },
      "outputs": [],
      "source": [
        "model_KNN.score(X_res,y_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUNjehsqP7s2"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_KNN.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eriWz2_QMKZ9"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(model_KNN, open(\"model_KNN_1.pkl\", \"wb\"))\n",
        "# load the model\n",
        "model = pickle.load(open(\"model_KNN_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfXQTtJ7NqMt"
      },
      "outputs": [],
      "source": [
        "cm3 = confusion_matrix(y_test, y_pred_KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz1XqYGniptY"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm3, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "# show the plot\n",
        "plt.savefig('KNN_all_CM.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XK4EK1Uipdr"
      },
      "outputs": [],
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred_KNN))  \n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred_KNN))  \n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_KNN)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGnMX-IWMpuF"
      },
      "outputs": [],
      "source": [
        "#Precision,recall,f1_score,cohen_kappa_score,auc.......\n",
        "print(\"Precision,recall,f1 score,cohen kappa score,auc.....\")\n",
        "print(\" \")\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_pred_KNN)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test,y_pred_KNN)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred_KNN)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test,  y_pred_KNN)\n",
        "print('ROC AUC: %f' % auc)\n",
        "#Cohen's kappa\n",
        "kappa=cohen_kappa_score(y_test,  y_pred_KNN)\n",
        "print('Cohen Kappa: %f' % kappa)\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGh72zkDEPrm"
      },
      "outputs": [],
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "lr_fpr, lr_tpr, thresholds = roc_curve(y_test, y_pred_KNN)\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='KNN')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "plt.savefig('KNN_all_auc.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3Qc6C-EHtxi"
      },
      "outputs": [],
      "source": [
        "model_KNN_1 = pickle.load(open(\"model_KNN_1.pkl\", \"rb\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNyKz_88i1BZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "%matplotlib inline\n",
        "\n",
        "feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model_KNN_1, X_test, y_test, n_repeats=10,random_state=0)\n",
        "\n",
        "features_names = ['0', '1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52']\n",
        "features = np.array(features_names)\n",
        "\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "\n",
        "plt.figure(figsize=(20, 14))\n",
        "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")\n",
        "\n",
        "variable=list()\n",
        "variable_droped=list()\n",
        "#Features importance before applying treshold......\n",
        "print('Features importance before applying threshold(mean)......')  \n",
        "\n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t  print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t \n",
        "\n",
        "#Features importance after applying treshold......\t \n",
        "print('\\n\\nFeatures importance after applying threshold(mean): %.5f\\n'%mean(perm_importance.importances_mean))  \n",
        "\t \n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t\n",
        " \n",
        "\tif(v>=mean(perm_importance.importances_mean)):\n",
        "    \n",
        "\t  #print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t\tvariable.append(i)\n",
        "\telse:\n",
        "\t\tvariable_droped.append(i)\n",
        "\n",
        "   \n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "#print('Threshold(Means of importances): %.5f' %mean(perm_importance.importances_mean))\n",
        "count=-1\n",
        "for i in variable:\n",
        "\tcount+=1\n",
        "\tprint('Feature no after thresholding:%s   ' %count + 'Feature no in main dataset:%s   ' % str(i) + 'Feature Name:%s   ' %feature_names[i] + 'Feature importance: %s' %perm_importance.importances_mean[i])\n",
        "print(variable) \n",
        "print(variable_droped) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DOiE-8Tt4CA"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(model_KNN, open(\"model_KNN_1.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6Lp4469uAxb"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "model = pickle.load(open(\"model_KNN_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot_yt1grroVJ"
      },
      "source": [
        "ADAboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d0ExD7kqpkB"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_ada =AdaBoostClassifier(algorithm='SAMME.R',\n",
        "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
        "                                                         class_weight=None,\n",
        "                                                         criterion='gini',\n",
        "                                                         max_depth=4,\n",
        "                                                         max_features=None,\n",
        "                                                         max_leaf_nodes=None,\n",
        "                                                         min_impurity_decrease=0.0,\n",
        "                                                         min_samples_leaf=5,\n",
        "                                                         min_samples_split=2,\n",
        "                                                         min_weight_fraction_leaf=0.0,\n",
        "                                                         random_state=None,\n",
        "                                                         splitter='best'),\n",
        "                   learning_rate=0.01, n_estimators=1000, random_state=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ghKRe2TIr2g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqGYZci2nlUE"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "t0=time.time()\n",
        "model_ada.fit(X_res, y_res)\n",
        "print (\"training time:\", round(time.time()-t0, 3), \"s\") # the time would be round to 3 decimal in seconds\n",
        "t1=time.time()\n",
        "y_pred_ada = model_ada.predict(X_test)\n",
        "print (\"predict time:\", round(time.time()-t1, 3), \"s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNYdQOswNkqG"
      },
      "outputs": [],
      "source": [
        "model_ada.score(X_res,y_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhW2wtBSn7fw"
      },
      "outputs": [],
      "source": [
        "model_ada.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLYrBDhzH4Wq"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump(model_ada, open(\"model_ADA_1.pkl\", \"wb\"))\n",
        "# load the model\n",
        "model = pickle.load(open(\"model_ADA_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqvuAXCMoTO4"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean\n",
        "%matplotlib inline\n",
        "\n",
        "feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model_ADA_1, X_test, y_test, n_repeats=10,random_state=0)\n",
        "\n",
        "features_names = ['0', '1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52']\n",
        "features = np.array(features_names)\n",
        "\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "\n",
        "plt.figure(figsize=(20, 14))\n",
        "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")\n",
        "\n",
        "variable=list()\n",
        "variable_droped=list()\n",
        "#Features importance before applying treshold......\n",
        "print('Features importance before applying threshold(mean)......')  \n",
        "\n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t  print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t \n",
        "\n",
        "#Features importance after applying treshold......\t \n",
        "print('\\n\\nFeatures importance after applying threshold(mean): %.5f\\n'%mean(perm_importance.importances_mean))  \n",
        "\t \n",
        "for i,v in enumerate(perm_importance.importances_mean):\n",
        "\t\n",
        " \n",
        "\tif(v>=mean(perm_importance.importances_mean)):\n",
        "    \n",
        "\t  #print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t\tvariable.append(i)\n",
        "\telse:\n",
        "\t\tvariable_droped.append(i)\n",
        "\n",
        "   \n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "#print('Threshold(Means of importances): %.5f' %mean(perm_importance.importances_mean))\n",
        "count=-1\n",
        "for i in variable:\n",
        "\tcount+=1\n",
        "\tprint('Feature no after thresholding:%s   ' %count + 'Feature no in main dataset:%s   ' % str(i) + 'Feature Name:%s   ' %feature_names[i] + 'Feature importance: %s' %perm_importance.importances_mean[i])\n",
        "print(variable) \n",
        "print(variable_droped) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSH_3CjVo2Uf"
      },
      "outputs": [],
      "source": [
        "cm3 = confusion_matrix(y_test, y_pred_ada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Flbyudho8Uq"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm3, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "# show the plot\n",
        "plt.savefig('ADA_all_CM.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMniQNeEo9KY"
      },
      "outputs": [],
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred_ada))  \n",
        "print('MSE:', metrics.mean_squared_error(y_test,y_pred_ada))  \n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_ada)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf-JTkNMpJHv"
      },
      "outputs": [],
      "source": [
        "#Precision,recall,f1_score,cohen_kappa_score,auc.......\n",
        "print(\"Precision,recall,f1 score,cohen kappa score,auc.....\")\n",
        "print(\" \")\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_pred_ada)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test,y_pred_ada)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred_ada)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test,  y_pred_ada)\n",
        "print('ROC AUC: %f' % auc)\n",
        "\n",
        "#Cohen's kappa\n",
        "kappa=cohen_kappa_score(y_test,  y_pred_ada)\n",
        "print('Cohen Kappa: %f' % kappa)\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zFp_G76EbTd"
      },
      "outputs": [],
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, y_pred_ada)\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ADA')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "plt.savefig('ADA_all_auc.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6owJWKQeb0Uf"
      },
      "outputs": [],
      "source": [
        "pickle.dump(model_ada, open(\"model_ADA_1.pkl\", \"wb\"))\n",
        "model = pickle.load(open(\"model_ADA_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjB3r-i0O7kM"
      },
      "outputs": [],
      "source": [
        "model.getparams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur8oWdU5PIn7"
      },
      "source": [
        "Result visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z00IjJ9G7XlZ"
      },
      "outputs": [],
      "source": [
        "Train_accuraccy=[98.47,99.98,99.21,98.35,99.12,99.98,99.94]\n",
        "Test_accuraccy=[98.21,99.32,98.00,98.30,98.64,98.38,98.81]\n",
        "roc=[98.21,99.32,98.00,98.00,98.64,98.36,98.81]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIcfS8lk7kk-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "  \n",
        "# creating the dataset\n",
        "data = {'Tremor':75, 'No Tremor':25}\n",
        "algo = ['LR','SVM','DT','RF','XGBoost','KNN','Adaboost']\n",
        "values = [98.47,99.98,99.21,98.35,99.12,99.98,99.94]\n",
        "  \n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# creating the bar plot\n",
        "plt.bar(algo, values, color ='orange',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\" Algorithms\")\n",
        "plt.ylabel(\"Train accuraccy\")\n",
        "plt.title(\"Algorithms vs Accuracy\")\n",
        "plt.savefig('Train_accuracy.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BROZnOrG-Qm3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "  \n",
        "# creating the dataset\n",
        "data = {'Tremor':75, 'No Tremor':25}\n",
        "algo = ['LR','SVM','DT','RF','XGBoost','KNN','Adaboost']\n",
        "values = [98.21,99.32,98.00,98.30,98.64,98.38,98.81]\n",
        "  \n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# creating the bar plot\n",
        "plt.bar(algo, values, color ='green',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\" Algorithms\")\n",
        "plt.ylabel(\"Test accuraccy\")\n",
        "plt.title(\"Algorithms vs Accuracy\")\n",
        "plt.savefig('Test_accuracy.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDihTecF_RcC"
      },
      "outputs": [],
      "source": [
        "# roc curve and auc\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# fit a model\n",
        "model = LogisticRegression(solver='lbfgs')\n",
        "model.fit(trainX, trainy)\n",
        "# predict probabilities\n",
        "lr_probs = model.predict_proba(testX)\n",
        "# keep probabilities for the positive outcome only\n",
        "lr_probs = lr_probs[:, 1]\n",
        "# calculate scores\n",
        "ns_auc = roc_auc_score(testy, ns_probs)\n",
        "lr_auc = roc_auc_score(testy, lr_probs)\n",
        "# summarize scores\n",
        "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "# calculate roc curves\n",
        "ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqofe0V_rDp3"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = pickle.load(open(\"model_ADA_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DadCjlKtKkL"
      },
      "outputs": [],
      "source": [
        "model.get_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z78r7VVe2cW8"
      },
      "outputs": [],
      "source": [
        "model1 = pickle.load(open(\"model_ada_last_1.pkl\", \"rb\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3OlmfnB2dzo"
      },
      "outputs": [],
      "source": [
        "model1.get_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bXaZLaVQN1z"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('ANN (97.22).h5')\n",
        "# use model to predict\n",
        "model.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yRv0uK8Q1E7"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXe03jZ7RfUC"
      },
      "outputs": [],
      "source": [
        "y_pred_final=list()\n",
        "for i in range(len(y_pred)):\n",
        "  if(y_pred[i]>0.5):\n",
        "    print('%.2f (expected %d)' % (1, y_test[i]))\n",
        "    y_pred_final.append(1)\n",
        " \n",
        "  else:\n",
        "        print('%.2f (expected %d)' % (0, y_test[i]))\n",
        "        y_pred_final.append(0)\n",
        " \n",
        " \n",
        "_, accuracy = model.evaluate(X_train,y_train.ravel())\n",
        "print('Training Accuracy: %.2f\\n\\n' % (accuracy*100))\n",
        "  \n",
        "_, accuracy = model.evaluate(X_test,y_test)\n",
        "print('Testing Accuracy: %.2f\\n\\n' % (accuracy*100))\n",
        "print(y_pred_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQTFmM3FQsiv"
      },
      "outputs": [],
      "source": [
        "# plot the roc curve for the model\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "lr_fpr, lr_tpr, _ = roc_curve(y_test, y_pred_final)\n",
        "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ANN')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "plt.savefig('ANN_all_auc.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpHSVlUgRJy6"
      },
      "outputs": [],
      "source": [
        "cm3 = confusion_matrix(y_test, y_pred_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QZktZYcRNIU"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(cm3, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')\n",
        "# show the plot\n",
        "plt.savefig('ANN_all_CM.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}