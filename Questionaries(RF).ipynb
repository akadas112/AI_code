{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wIAtUtZxTZO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_kq4zYg-Ei_"
      },
      "source": [
        "#Importing important files....\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.inspection import permutation_importance\n",
        "from statistics import mean\n",
        "from sklearn import tree\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fYejI96-Ed2"
      },
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Dataset/combine dataset.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TbCJwh3-Ea_"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE62W7lI-EX2"
      },
      "source": [
        "#feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "#Defining features(X) and labels(Y)....\n",
        "X = df.drop(['Status','PATNO','EVENT_ID', 'NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2TURN','NP2RISE','NP2WALK','NP2FREZ','NP3RIGN','PN3RIGRL','NP3RIGLL','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ'],axis =1).values\n",
        "y = df['Status'].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKZWJkT4-EVU"
      },
      "source": [
        "X = pd.DataFrame(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5XN2fHM-ESU"
      },
      "source": [
        "#Checking is any nan value available or not\n",
        "np.any(np.isnan(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TisOPS3z-EPc"
      },
      "source": [
        "#Missing value handle\n",
        "imputer = SimpleImputer(missing_values = np.NaN, strategy = 'mean')\n",
        "imputer = imputer.fit(X)\n",
        "X = imputer.transform(X)\n",
        "final_dataset = pd.DataFrame(X)\n",
        "final_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwSNPGYg-EMs"
      },
      "source": [
        "#Feature scaling\n",
        "feature_X = StandardScaler().fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGg-Ddzi-EJv"
      },
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y == 1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y == 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiTatcAC-EHM"
      },
      "source": [
        "#over sampling\n",
        "sm = SMOTE(random_state = 2)\n",
        "X_res, y_res = sm.fit_sample(feature_X, y.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res == 1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res == 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3c9KSxM-EEU"
      },
      "source": [
        "#Train and test data set split.....\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmv09Ddb-EBU"
      },
      "source": [
        "#Definimng model\n",
        "model_rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=3, max_features='auto',\n",
        "                       max_leaf_nodes=None, max_samples=None,\n",
        "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                       min_samples_leaf=1, min_samples_split=2,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZcZ6HYN-D-c"
      },
      "source": [
        "#Fitting the defined model\n",
        "model_rf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B2b8zVo-D48"
      },
      "source": [
        "#Prediction\n",
        "y_pred = model_rf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOC9oIFG-D10"
      },
      "source": [
        "model_rf.score(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkZ_TS-D-DxN"
      },
      "source": [
        "#Model score\n",
        "model_rf.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_U-hr_N-uGl"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,7))\n",
        "sn.heatmap(cm, annot=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8TQX8Md-udl"
      },
      "source": [
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5958nib-3VM"
      },
      "source": [
        "#Precision,recall,f1_score,cohen_kappa_score,auc.......\n",
        "print(\"Precision,recall,f1 score,cohen kappa score,auc.....\")\n",
        "print(\" \")\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test,y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1 score: %f' % f1)\n",
        "\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test,  y_pred)\n",
        "print('ROC AUC: %f' % auc)\n",
        "print(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lysavlqx9pGp"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(model_rf, open(\"model_rf_last_1.pkl\", \"wb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8TymyvN9yXd"
      },
      "source": [
        "# load the model\n",
        "model = pickle.load(open(\"model_rf_last_1.pkl\", \"rb\"))\n",
        "\n",
        "# use model to predict\n",
        "model.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML6ySjgt0NN7"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "feature_names = ['NP1SLPN', 'NP1SLPD','NP1PAIN','NP1URIN','NP1CNST','NP1LTHD','NP1FATG','NP2SPCH','NP2SALV','NP2SWAL','NP2EAT','NP2DRES','NP2HYGN','NP2HWRT','NP2HOBB','NP2TURN','NP2TRMR','NP2RISE','NP2WALK','NP2FREZ','NP3SPCH','NP3FACXP','NP3RIGN','NP3RIGRU','NP3RIGLU','PN3RIGRL','NP3RIGLL','NP3FTAPR','NP3FTAPL','NP3HMOVR','NP3HMOVL','NP3PRSPR','NP3PRSPL','NP3TTAPR','NP3TTAPL','NP3LGAGR','NP3LGAGL','NP3RISNG','NP3GAIT','NP3FRZGT','NP3PSTBL','NP3POSTR','NP3BRADY','NP3PTRMR','NP3PTRML','NP3KTRMR','NP3KTRML','NP3RTARU','NP3RTALU','NP3RTARL','NP3RTALL','NP3RTALJ','NP3RTCON']\n",
        "\n",
        "\n",
        "perm_importance = permutation_importance(model_rf, X_test, y_test, n_repeats=10,random_state=0)\n",
        "\n",
        "features_names = ['0', '1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52']\n",
        "features = np.array(features_names)\n",
        "\n",
        "sorted_idx = perm_importance.importances_mean.argsort()\n",
        "\n",
        "plt.figure(figsize=(20, 14))\n",
        "plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
        "plt.xlabel(\"Permutation Importance\")\n",
        "imp=perm_importance.importances_mean\n",
        "im=list()\n",
        "for i,v in enumerate(imp):\n",
        "\n",
        "\t#if(v>=mean(perm_importance.importances_mean)):\n",
        "\n",
        "\t  print('Feature: %0d, Score: %.5f' % (i,v))\n",
        "\t  im.append(i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print('Threshold(Means of importances): %.5f' %mean(perm_importance.importances_mean))\n",
        "print(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoJ3wG5b7s4Q"
      },
      "source": [
        "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)\n",
        "tree.plot_tree(model_rf.estimators_[9],\n",
        "               feature_names = feature_names,\n",
        "               class_names=['0','1'],\n",
        "               filled = True);\n",
        "fig.savefig('rf_individualtree_final_10.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFrTF24n6fP9"
      },
      "source": [
        "train_accuracy =[92.21,94.35,95.3,95.92,96.44,96.69,96.4,96.98,96.93,97.37,97.54,97.66,97.88]\n",
        "test_accuracy =[93.75,94.18,95.92,96.47,96.6,96.81,96.81,96.98,97.32,97.32,97.49,97.74,97.87]\n",
        "\n",
        "features = range(1,14)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(features, train_accuracy, 'g', label='Training accuraccy')\n",
        "plt.plot(features, test_accuracy, 'b', label='Test accuraccy')\n",
        "plt.title(' Accuracy vs Feature Number(Random Forest)')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('RF_accuraccy_vs_features.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUTRjwHM77CE"
      },
      "source": [
        "MSE_loss =[0.062,0.058,0.04,0.035,0.033,0.031,0.031,0.03,0.026,0.026,0.025,0.022,0.021]\n",
        "RMSE_loss =[0.249,0.241,0.201,0.187,0.184,0.178,0.178,0.173,0.163,0.163,0.158,0.15,0.145]\n",
        "\n",
        "features = range(1,14)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(features, MSE_loss, 'red', label='Loss(MSE and MAE )')\n",
        "plt.plot(features,RMSE_loss, 'orange', label='Loss(RMSE)')\n",
        "plt.title(' Model Loss vs Features(Random Forest)')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Model Loss')\n",
        "plt.legend()\n",
        "plt.savefig('RF_loss_vs_features.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}